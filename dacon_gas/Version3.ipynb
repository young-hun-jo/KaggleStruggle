{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "approximate-precipitation",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#버전-2까지-수행하고-난-후의-개선사항\" data-toc-modified-id=\"버전-2까지-수행하고-난-후의-개선사항-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>버전 2까지 수행하고 난 후의 개선사항</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#데이터-로드-및-FE-함수\" data-toc-modified-id=\"데이터-로드-및-FE-함수-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>데이터 로드 및 FE 함수</a></span></li><li><span><a href=\"#구분끼리-유형-나누어서-예측해보기\" data-toc-modified-id=\"구분끼리-유형-나누어서-예측해보기-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>구분끼리 유형 나누어서 예측해보기</a></span></li><li><span><a href=\"#다음에-할-일\" data-toc-modified-id=\"다음에-할-일-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>다음에 할 일</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-elevation",
   "metadata": {},
   "source": [
    "# 버전 2까지 수행하고 난 후의 개선사항\n",
    "- 날씨 데이터 사용의 효과가 그닥.. -> 날씨 데이터 그만파자.. 오히려 빼는게 좋을 수도.. -> 자기상관변수 증감률 데이터 FE하기!\n",
    "- 모든 데이터를 다 사용했을 때가 Test 데이터에 대해 리더보드 결과는 더 좋음..? 두 가지 경우 모두 테스트 해야 할듯..\n",
    "- 다른 모델들 사용 -> 여러가지 모델...뭘 사용할까!?\n",
    "- 함수화 할것\n",
    "    - 데이터 로드 및 FE 함수\n",
    "    - 모델링 후 학습, 검증 결과 출력하는 함수\n",
    "    - 모델링 학습 후 최종 Test 출력하는 함수\n",
    "    - 제출하는 csv 파일 만드는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-country",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 FE 함수\n",
    "- 날씨 데이터는 빼고 시도..\n",
    "- 증감률 추가해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "shaped-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383208, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "def load_datasets(path) -> pd.DataFrame:\n",
    "    train = pd.read_csv(os.path.join(path, '한국가스공사_시간별 공급량_20181231.csv'),\n",
    "                        encoding='cp949')\n",
    "    test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    # test 데이터 전처리\n",
    "    test['연월일'] = test['일자|시간|구분'].str.split(' ', expand=True)[0]\n",
    "    test['시간'] = test['일자|시간|구분'].str.split(' ', expand=True)[1].astype(int)\n",
    "    test['구분'] = test['일자|시간|구분'].str.split(' ', expand=True)[2]\n",
    "    del test['일자|시간|구분']\n",
    "\n",
    "    data = pd.concat([train, test], axis=0)\n",
    "    data['연월일'] = pd.to_datetime(data['연월일'])\n",
    "    return data\n",
    "\n",
    "def load_weather() -> pd.DataFrame:\n",
    "    db = pymysql.connect(host='localhost', port=3306, user='younghun', password='watson1259',\n",
    "                        db='dacon_gas_weather_db', charset='utf8')\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT datetime, avg_temp, min_temp, max_temp,\\\n",
    "              NULLIF(sum_rain, '') as sum_rain, avg_wind, avg_humid,\\\n",
    "              sum_gsr, NULLIF(ddmefs, '') as ddmefs, avg_ts \\\n",
    "              FROM weather ORDER BY datetime\"\n",
    "    \n",
    "    weather = pd.read_sql(sql, db)\n",
    "    weather = weather.fillna(0.)\n",
    "    \n",
    "    return weather\n",
    "    \n",
    "def merge_gas_weather(path):\n",
    "    gas = load_datasets(path)\n",
    "    weather = load_weather()\n",
    "    gas_weather = gas.merge(weather, how='left', left_on='연월일', right_on='datetime')\n",
    "    del gas_weather['datetime']\n",
    "    \n",
    "    return gas_weather\n",
    "\n",
    "def make_datetime_vars(data) -> pd.DataFrame:\n",
    "    data['year'] = data['연월일'].dt.year\n",
    "    data['month'] = data['연월일'].dt.month\n",
    "    data['day'] = data['연월일'].dt.day\n",
    "    data['week_no'] = data['연월일'].dt.strftime(\"%V\").astype(int)\n",
    "    data['dayofweek'] = data['연월일'].dt.day_name()\n",
    "    data['weekend_yn'] = np.where(data['dayofweek'].isin(['Saturday', 'Sunday']), 1, 0)\n",
    "    data['dayofyear'] = data['연월일'].dt.dayofyear\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def change_dates(row):\n",
    "    if row['시간'] == 24:\n",
    "        row['연월일'] += pd.DateOffset(days=1)\n",
    "        row['시간'] = 0\n",
    "    return row\n",
    "\n",
    "\n",
    "def extract_need_data(df):\n",
    "    \"\"\" 연월일 날짜 포맷 바꾸고 매년 01-01~03-31 기간 데이터만 추출\"\"\"\n",
    "    df = df.apply(change_dates, axis=1)\n",
    "    df['시간'] = df['시간'].apply(lambda x: str(x) if x >= 10 else '0' + str(x))\n",
    "    df['연월일'] = df['연월일'].astype(str)\n",
    "    df['datetime'] = df['연월일'] + ' ' + df['시간']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H')\n",
    "\n",
    "    df['prev_datetime'] = df['datetime'] - pd.DateOffset(years=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_autocorr_vars(df, gubun='A'):\n",
    "    sub_df = df[df['구분'] == gubun]\n",
    "    # 일년 전 그 시간대 공급량\n",
    "    sub_df['prev_year_공급량'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                          sub_df['datetime'].dt.hour])['공급량'].shift()\n",
    "#     # 이년 전 공급량 파생변수 생성\n",
    "#     sub_df['prev_two_year_공급량'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "#                                               sub_df['datetime'].dt.hour])['공급량'].shift(2)\n",
    "    # 일년 전 평균 공급량\n",
    "    sub_df['prev_year'] = sub_df['prev_datetime'].dt.year\n",
    "    prev_year_mean_df = sub_df.groupby([sub_df['datetime'].dt.year])['공급량'].mean()\n",
    "    prev_year_mean_dict = dict(zip(prev_year_mean_df.index, prev_year_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_avg_공급량'] = sub_df['prev_year'].map(prev_year_mean_dict)\n",
    "    # 일년 전 월별 평균 공급량\n",
    "    prev_month_mean_df = sub_df.groupby([sub_df['datetime'].dt.year, sub_df['datetime'].dt.month])['공급량'].mean()\n",
    "    prev_month_mean_dict = dict(zip(prev_month_mean_df.index, prev_month_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_month'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                        sub_df['prev_datetime'].dt.month.values.reshape(-1, )))\n",
    "    sub_df['prev_month_avg_공급량'] = sub_df['prev_year_month'].map(prev_month_mean_dict)\n",
    "    # 일년 전 월-일자별 평균 공급량\n",
    "    prev_month_day_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                           sub_df['datetime'].dt.month,\n",
    "                                           sub_df['datetime'].dt.day])['공급량'].mean()\n",
    "    prev_month_day_mean_dict = dict(zip(prev_month_day_mean_df.index, prev_month_day_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_day'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.day.values.reshape(-1, )))\n",
    "    sub_df['prev_month_day_avg_공급량'] = sub_df['prev_year_month_day'].map(prev_month_day_mean_dict)\n",
    "    # 일년 전 월-시간 별 평균 공급량\n",
    "    prev_month_hour_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                            sub_df['datetime'].dt.month,\n",
    "                                            sub_df['datetime'].dt.hour])['공급량'].mean()\n",
    "    prev_month_hour_mean_dict = dict(zip(prev_month_hour_mean_df.index, prev_month_hour_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_hour'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.hour.values.reshape(-1, )))\n",
    "    sub_df['prev_month_hour_avg_공급량'] = sub_df['prev_year_month_hour'].map(prev_month_hour_mean_dict)\n",
    "    # 일년 전 그 날의 기상 변수 FE\n",
    "    weather_cols = ['avg_temp','min_temp','max_temp','sum_rain','avg_wind','avg_humid','sum_gsr','ddmefs','avg_ts']\n",
    "    for col in weather_cols:\n",
    "        sub_df[f'prev_year_{col}'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                                  sub_df['datetime'].dt.hour])[col].shift()\n",
    "        sub_df[f'prev_year_{col}'] = pd.to_numeric(sub_df[f'prev_year_{col}'], downcast=\"float\")\n",
    "\n",
    "    # 필요한 칼럼들만 추출\n",
    "#     used_cols = ['연월일', '시간', 'datetime', '구분', 'prev_year_공급량',\n",
    "#                  'prev_two_year_공급량', 'prev_year_avg_공급량', 'prev_month_avg_공급량', 'prev_month_day_avg_공급량',\n",
    "#                  'prev_month_hour_avg_공급량', '공급량']\n",
    "    used_cols = ['연월일', '시간', 'datetime', '구분', 'prev_year_공급량', 'prev_year_avg_공급량',\n",
    "                 'prev_month_avg_공급량', 'prev_month_day_avg_공급량', 'prev_month_hour_avg_공급량']\n",
    "    weather_cols = [f'prev_year_{col}' for col in weather_cols]\n",
    "    used_cols += weather_cols + ['공급량']\n",
    "    sub_df = sub_df[used_cols]\n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def fe_autocorr_vars(df):\n",
    "    final_df = pd.DataFrame()\n",
    "    gubun_cols = ['A','B','C','D','E','G','H']\n",
    "    for gubun in tqdm(gubun_cols):\n",
    "        sub_df = make_autocorr_vars(df, gubun=gubun)\n",
    "        final_df = pd.concat([final_df, sub_df], axis=0)\n",
    "    return final_df\n",
    "\n",
    "def change_dates_adversely(row):\n",
    "    if row['datetime'].hour == 0:\n",
    "        row['연월일'] -= pd.DateOffset(days=1)\n",
    "        row['시간'] = 24\n",
    "    return row\n",
    "\n",
    "def change_date_format(df):\n",
    "    df['연월일'] = pd.to_datetime(df['연월일'])\n",
    "    df['시간'] = df['시간'].astype(int)\n",
    "    df = df.apply(change_dates_adversely, axis=1)\n",
    "    \n",
    "    del df['datetime']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas'\n",
    "gas_weather = merge_gas_weather(path)\n",
    "dataset = make_datetime_vars(gas_weather)\n",
    "dataset = extract_need_data(dataset)\n",
    "final_df = fe_autocorr_vars(dataset)\n",
    "final_df = change_date_format(final_df)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "print(final_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "featured-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014년부터 데이터 추출하는데, 매변 01-03월만 사용할지, 전체 사용할지 함수\n",
    "def extract_dataset(final_df, split=False):\n",
    "    # 2014-01-01부터 사용\n",
    "    cond = final_df['연월일'].dt.year >= 2014\n",
    "    final_df = final_df[cond]\n",
    "    if split:\n",
    "        cond0103 = (final_df['연월일'].dt.month >= 1) & (final_df['연월일'].dt.month <= 3)\n",
    "        final_df = final_df[cond0103]\n",
    "        return final_df\n",
    "    else:\n",
    "        return final_df\n",
    "    \n",
    "# 구분 없이 통합 예측 or 구분 유형대로 예측하기 위한 데이터 포맷 형태\n",
    "def predict_simultaneously(final_df, simultaneously=False):\n",
    "    if simultaneously:\n",
    "        # 구분 원-핫 인코딩\n",
    "        final_df[['B','C','D','E','G','H']] = pd.get_dummies(final_df['구분'], drop_first=True).values\n",
    "        cols_order = final_df.columns.tolist()\n",
    "        cols_order.remove('공급량')\n",
    "        cols_order.insert(len(cols_order), '공급량')\n",
    "        final_df = final_df[cols_order]\n",
    "        return final_df\n",
    "    else:\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-dairy",
   "metadata": {},
   "source": [
    "### 구분끼리 유형 나누어서 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "sweet-split",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 구분 유형별로 predict\n",
    "def get_NMAE(true, pred):\n",
    "    mae = np.abs(true-pred)/true\n",
    "    nmae = np.mean(mae)\n",
    "    return nmae\n",
    "\n",
    "def predict_each_gubun(final_df, model, submission_csv, simultaneously=True):\n",
    "    # 통합해서 예측\n",
    "    if simultaneously:\n",
    "        final_df = final_df.set_index(['연월일', '시간', '구분'])\n",
    "        idx_level = final_df.index.get_level_values\n",
    "        #======================\n",
    "        # Train, Valid로 성능 검증\n",
    "        #======================\n",
    "        train = final_df[(idx_level(0) < '2018-01-01')]\n",
    "        train = train.fillna(method='ffill')\n",
    "        valid = final_df[(idx_level(0) >=' 2018-01-01') & (idx_level(0) <= '2018-03-31')]\n",
    "        # X, y 분할\n",
    "        X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "        X_valid, y_valid = valid.iloc[:, :-1].values, valid['공급량']\n",
    "        # fit\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict\n",
    "        train_pred = model.predict(X_train)\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        # evaluate\n",
    "        train_nmae = get_NMAE(y_train, train_pred)\n",
    "        valid_nmae = get_NMAE(y_valid, valid_pred)\n",
    "        print(f'# 통합 예측 - Train NAME:', round(train_nmae, 3))\n",
    "        print(f'# 통합 예측 - Valid NMAE:', round(valid_nmae, 3))\n",
    "        #======================\n",
    "        # 모두 학습시키고 Test로 예측\n",
    "        #======================\n",
    "        train = final_df[(idx_level(0) < '2019-01-01')]\n",
    "        train = train.fillna(method='ffill')\n",
    "        test = final_df[(idx_level(0) >= '2019-01-01')]\n",
    "        # X,y 분할\n",
    "        X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "        X_test = test.iloc[:, :-1].fillna(method='ffill').values\n",
    "        # fit\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict\n",
    "        test_pred = model.predict(X_test)\n",
    "        submission_csv['공급량'] = test_pred\n",
    "        return submission_csv\n",
    "        \n",
    "    else:\n",
    "        cols = ['A', 'B', 'C', 'D', 'E', 'G', 'H']\n",
    "        total_test_pred = np.array([])\n",
    "        for col in cols:\n",
    "            gubun_df = final_df[final_df['구분'] == col]\n",
    "            gubun_df = gubun_df.set_index(['연월일','시간','구분'])\n",
    "\n",
    "            idx_level = gubun_df.index.get_level_values\n",
    "            #======================\n",
    "            # Train, Valid로 성능 검증\n",
    "            #======================\n",
    "            train = gubun_df[(idx_level(0) < '2018-01-01')]\n",
    "            train = train.fillna(method='ffill')  # 결측치 있으면 안도는 모델용\n",
    "            valid = gubun_df[(idx_level(0) >= '2018-01-01') & (idx_level(0) <= '2018-03-31')]\n",
    "            # X, y 분할\n",
    "            X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "            X_valid, y_valid = valid.iloc[:, :-1].values, valid['공급량']\n",
    "            # fit\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict\n",
    "            train_pred = model.predict(X_train)\n",
    "            valid_pred = model.predict(X_valid)\n",
    "            # evaluate\n",
    "            train_nmae = get_NMAE(y_train, train_pred)\n",
    "            valid_nmae = get_NMAE(y_valid, valid_pred)\n",
    "            print(f'# {col} - Train NAME:', round(train_nmae, 3))\n",
    "            print(f'# {col} - Valid NMAE:', round(valid_nmae, 3))\n",
    "            print()\n",
    "            #======================\n",
    "            # 모두 학습시키고 Test로 예측\n",
    "            #======================\n",
    "            train = gubun_df[(idx_level(0) < '2019-01-01')]\n",
    "            train = train.fillna(method='ffill')\n",
    "            test = gubun_df[(idx_level(0) >= '2019-01-01')]\n",
    "            # X,y 분할\n",
    "            X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "            X_test = test.iloc[:, :-1]\n",
    "            X_test = X_test.fillna(method='ffill')  # 결측치 있으면 안도는 모델용\n",
    "            X_test = X_test.values\n",
    "            # fit\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict\n",
    "            test_pred = model.predict(X_test)\n",
    "            total_test_pred = np.append(total_test_pred, test_pred)\n",
    "\n",
    "        submission_csv['공급량'] = total_test_pred\n",
    "        return submission_csv, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "thermal-medium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# A - Train NAME: 0.107\n",
      "# A - Valid NMAE: 0.16\n",
      "\n",
      "[15:49:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:49:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# B - Train NAME: 0.116\n",
      "# B - Valid NMAE: 0.187\n",
      "\n",
      "[15:49:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:49:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# C - Train NAME: 1.104\n",
      "# C - Valid NMAE: 0.141\n",
      "\n",
      "[15:49:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:49:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# D - Train NAME: 0.109\n",
      "# D - Valid NMAE: 0.15\n",
      "\n",
      "[15:49:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:49:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# E - Train NAME: 0.096\n",
      "# E - Valid NMAE: 0.156\n",
      "\n",
      "[15:49:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:49:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# G - Train NAME: 0.103\n",
      "# G - Valid NMAE: 0.172\n",
      "\n",
      "[15:49:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:49:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# H - Train NAME: 0.113\n",
      "# H - Valid NMAE: 0.162\n",
      "\n",
      "[15:49:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "# 01-03월만 추출\n",
    "df = extract_dataset(final_df, split=False)\n",
    "# 구분 분리안하고 동시에 예측\n",
    "df = predict_simultaneously(df, simultaneously=False)\n",
    "\n",
    "# submit\n",
    "submission_csv = pd.read_csv('/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/sample_submission.csv')\n",
    "# model\n",
    "lgbm = LGBMRegressor(n_estimators=100)\n",
    "xgb = XGBRegressor(n_estimators=100)\n",
    "voting_reg = VotingRegressor(estimators=[('lgbm', lgbm),\n",
    "                                        ('xgb', xgb)])\n",
    "\n",
    "submission_csv, test = predict_each_gubun(final_df=df, model=voting_reg, submission_csv=submission_csv,\n",
    "                                          simultaneously=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "indian-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/submission/'\n",
    "\n",
    "# 파일명 -> 01-03월 분리여부_구분유형분리여부_모델종류_trainNMAE_validNMAE.csv\n",
    "submission_csv.to_csv(sub_path+'0103True_SimulFalse_xgb+lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-enough",
   "metadata": {},
   "source": [
    "- 01-03월: False, 통합예측 : False, XGB+LGBM => 1.5->1.40로 성능 확 개선!\n",
    "- 01-03월: True, 통합예측 : False, XGB+LGBM => 1.5로 다시 늘어남 => 따라서 예측은 통합예측으로 수행하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-sarah",
   "metadata": {},
   "source": [
    "### 다음에 할 일\n",
    "- **시계열 데이터는 모두 사용하기(split=False)** (01-03월만 추출 X)\n",
    "- **구분유형 분리해서 개별로 예측(simultaneously=False)**\n",
    "- 현재 사용한 변수:\n",
    "    - 자기상관 변수\n",
    "        - 1년 전 그시간 공급량\n",
    "        - 1년 전 연도별 평균 공급량\n",
    "        - 1년 전 연-월별 평균 공급량\n",
    "        - 1년 전 연-월-일자별 평균 공급량\n",
    "        - 1년 전 연-월-시간대별 평균 공급량\n",
    "    - 날씨 변수\n",
    "        - 1년 전 평균 기온\n",
    "        - 1년 전 최저 기온\n",
    "        - 1년 전 최고 기온\n",
    "        - 1년 전 강수합계량\n",
    "        - 1년 전 평균풍속\n",
    "        - 1년 전 평균상대습도\n",
    "        - 1년 전 평균합계일사량\n",
    "        - 1년 전 평균신적설\n",
    "        - 1년 전 평균지면온도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "lasting-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자기상관 변수 더 만들자..! => 변화율(ratio)\n",
    "# 1. 일년전 그 년도의 평균 공급량 대비 일년 전 공급량이 얼마나 증가했는지?\n",
    "# 2. 일년전 그 년도의 월별 평균 공급량 대비 일년 전 공급량이 얼마나 증가했는지?\n",
    "# 3. 일년전 그 년도의 월-일자별 평균 공급량 대비 일년 전 공급량이 얼마나 증가했는지?\n",
    "# 4. 일년전 그 년도의 월-시간별 평균 공급량 대비 일년 전 공급량이 얼마나 증가했는지?\n",
    "### 우선 위 변수들 FE하고 성능 테스트하기 -> 만약 성능 떨어진다면 LGBM으로 한번 모델링하고 feature Importance보고 날씨 변수 drop여부 결정 \n",
    "### -> drop하게 된다면 drop하고 재 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-projection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
