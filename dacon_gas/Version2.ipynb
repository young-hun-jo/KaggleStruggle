{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "general-story",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#데이터-로드-->-날짜,-자기상관-변수-FE-함수화\" data-toc-modified-id=\"데이터-로드-->-날짜,-자기상관-변수-FE-함수화-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>데이터 로드 -&gt; 날짜, 자기상관 변수 FE 함수화</a></span></li><li><span><a href=\"#첫-번째-제출:-1년-전-변수까지만-포함해서\" data-toc-modified-id=\"첫-번째-제출:-1년-전-변수까지만-포함해서-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>첫 번째 제출: 1년 전 변수까지만 포함해서</a></span></li><li><span><a href=\"#두-번째-제출:-기상-데이터-~2018-12-31년것까지-가져와서-사용-후-제출\" data-toc-modified-id=\"두-번째-제출:-기상-데이터-~2018-12-31년것까지-가져와서-사용-후-제출-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>두 번째 제출: 기상 데이터 ~2018-12-31년것까지 가져와서 사용 후 제출</a></span></li><li><span><a href=\"#버전-2-결론\" data-toc-modified-id=\"버전-2-결론-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>버전 2 결론</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-firewall",
   "metadata": {},
   "source": [
    "## 데이터 로드 -> 날짜, 자기상관 변수 FE 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "combined-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383208, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "def load_datasets(path) -> pd.DataFrame:\n",
    "    train = pd.read_csv(os.path.join(path, '한국가스공사_시간별 공급량_20181231.csv'),\n",
    "                        encoding='cp949')\n",
    "    test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    # test 데이터 전처리\n",
    "    test['연월일'] = test['일자|시간|구분'].str.split(' ', expand=True)[0]\n",
    "    test['시간'] = test['일자|시간|구분'].str.split(' ', expand=True)[1].astype(int)\n",
    "    test['구분'] = test['일자|시간|구분'].str.split(' ', expand=True)[2]\n",
    "    del test['일자|시간|구분']\n",
    "\n",
    "    data = pd.concat([train, test], axis=0)\n",
    "    data['연월일'] = pd.to_datetime(data['연월일'])\n",
    "    return data\n",
    "\n",
    "def load_weather() -> pd.DataFrame:\n",
    "    db = pymysql.connect(host='localhost', port=3306, user='younghun', password='watson1259',\n",
    "                        db='dacon_gas_weather_db', charset='utf8')\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT datetime, avg_temp, min_temp, max_temp,\\\n",
    "              NULLIF(sum_rain, '') as sum_rain, avg_wind, avg_humid,\\\n",
    "              sum_gsr, NULLIF(ddmefs, '') as ddmefs, avg_ts \\\n",
    "              FROM weather ORDER BY datetime\"\n",
    "    \n",
    "    weather = pd.read_sql(sql, db)\n",
    "    weather = weather.fillna(0.)\n",
    "    \n",
    "    return weather\n",
    "    \n",
    "def merge_gas_weather(path):\n",
    "    gas = load_datasets(path)\n",
    "    weather = load_weather()\n",
    "    gas_weather = gas.merge(weather, how='left', left_on='연월일', right_on='datetime')\n",
    "    del gas_weather['datetime']\n",
    "    \n",
    "    return gas_weather\n",
    "\n",
    "def make_datetime_vars(data) -> pd.DataFrame:\n",
    "    data['year'] = data['연월일'].dt.year\n",
    "    data['month'] = data['연월일'].dt.month\n",
    "    data['day'] = data['연월일'].dt.day\n",
    "    data['week_no'] = data['연월일'].dt.strftime(\"%V\").astype(int)\n",
    "    data['dayofweek'] = data['연월일'].dt.day_name()\n",
    "    data['weekend_yn'] = np.where(data['dayofweek'].isin(['Saturday', 'Sunday']), 1, 0)\n",
    "    data['dayofyear'] = data['연월일'].dt.dayofyear\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def change_dates(row):\n",
    "    if row['시간'] == 24:\n",
    "        row['연월일'] += pd.DateOffset(days=1)\n",
    "        row['시간'] = 0\n",
    "    return row\n",
    "\n",
    "\n",
    "def extract_need_data(df):\n",
    "    \"\"\" 연월일 날짜 포맷 바꾸고 매년 01-01~03-31 기간 데이터만 추출\"\"\"\n",
    "    df = df.apply(change_dates, axis=1)\n",
    "    df['시간'] = df['시간'].apply(lambda x: str(x) if x >= 10 else '0' + str(x))\n",
    "    df['연월일'] = df['연월일'].astype(str)\n",
    "    df['datetime'] = df['연월일'] + ' ' + df['시간']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H')\n",
    "\n",
    "    df['prev_datetime'] = df['datetime'] - pd.DateOffset(years=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_autocorr_vars(df, gubun='A'):\n",
    "    sub_df = df[df['구분'] == gubun]\n",
    "    # 일년 전 그 시간대 공급량\n",
    "    sub_df['prev_year_공급량'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                          sub_df['datetime'].dt.hour])['공급량'].shift()\n",
    "#     # 이년 전 공급량 파생변수 생성\n",
    "#     sub_df['prev_two_year_공급량'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "#                                               sub_df['datetime'].dt.hour])['공급량'].shift(2)\n",
    "    # 일년 전 평균 공급량\n",
    "    sub_df['prev_year'] = sub_df['prev_datetime'].dt.year\n",
    "    prev_year_mean_df = sub_df.groupby([sub_df['datetime'].dt.year])['공급량'].mean()\n",
    "    prev_year_mean_dict = dict(zip(prev_year_mean_df.index, prev_year_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_avg_공급량'] = sub_df['prev_year'].map(prev_year_mean_dict)\n",
    "    # 일년 전 월별 평균 공급량\n",
    "    prev_month_mean_df = sub_df.groupby([sub_df['datetime'].dt.year, sub_df['datetime'].dt.month])['공급량'].mean()\n",
    "    prev_month_mean_dict = dict(zip(prev_month_mean_df.index, prev_month_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_month'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                        sub_df['prev_datetime'].dt.month.values.reshape(-1, )))\n",
    "    sub_df['prev_month_avg_공급량'] = sub_df['prev_year_month'].map(prev_month_mean_dict)\n",
    "    # 일년 전 월-일자별 평균 공급량\n",
    "    prev_month_day_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                           sub_df['datetime'].dt.month,\n",
    "                                           sub_df['datetime'].dt.day])['공급량'].mean()\n",
    "    prev_month_day_mean_dict = dict(zip(prev_month_day_mean_df.index, prev_month_day_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_day'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.day.values.reshape(-1, )))\n",
    "    sub_df['prev_month_day_avg_공급량'] = sub_df['prev_year_month_day'].map(prev_month_day_mean_dict)\n",
    "    # 일년 전 월-시간 별 평균 공급량\n",
    "    prev_month_hour_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                            sub_df['datetime'].dt.month,\n",
    "                                            sub_df['datetime'].dt.hour])['공급량'].mean()\n",
    "    prev_month_hour_mean_dict = dict(zip(prev_month_hour_mean_df.index, prev_month_hour_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_hour'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.hour.values.reshape(-1, )))\n",
    "    sub_df['prev_month_hour_avg_공급량'] = sub_df['prev_year_month_hour'].map(prev_month_hour_mean_dict)\n",
    "    # 일년 전 그 날의 기상 변수 FE\n",
    "    weather_cols = ['avg_temp','min_temp','max_temp','sum_rain','avg_wind','avg_humid','sum_gsr','ddmefs','avg_ts']\n",
    "    for col in weather_cols:\n",
    "        sub_df[f'prev_year_{col}'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                                  sub_df['datetime'].dt.hour])[col].shift()\n",
    "        sub_df[f'prev_year_{col}'] = pd.to_numeric(sub_df[f'prev_year_{col}'], downcast=\"float\")\n",
    "\n",
    "    # 필요한 칼럼들만 추출\n",
    "#     used_cols = ['연월일', '시간', 'datetime', '구분', 'prev_year_공급량',\n",
    "#                  'prev_two_year_공급량', 'prev_year_avg_공급량', 'prev_month_avg_공급량', 'prev_month_day_avg_공급량',\n",
    "#                  'prev_month_hour_avg_공급량', '공급량']\n",
    "    used_cols = ['연월일', '시간', 'datetime', '구분', 'prev_year_공급량', 'prev_year_avg_공급량',\n",
    "                 'prev_month_avg_공급량', 'prev_month_day_avg_공급량', 'prev_month_hour_avg_공급량']\n",
    "    weather_cols = [f'prev_year_{col}' for col in weather_cols]\n",
    "    used_cols += weather_cols + ['공급량']\n",
    "    sub_df = sub_df[used_cols]\n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def fe_autocorr_vars(df):\n",
    "    final_df = pd.DataFrame()\n",
    "    gubun_cols = df['구분'].unique()\n",
    "    for gubun in tqdm(gubun_cols):\n",
    "        sub_df = make_autocorr_vars(df, gubun=gubun)\n",
    "        final_df = pd.concat([final_df, sub_df], axis=0)\n",
    "    return final_df\n",
    "\n",
    "def change_dates_adversely(row):\n",
    "    if row['datetime'].hour == 0:\n",
    "        row['연월일'] -= pd.DateOffset(days=1)\n",
    "        row['시간'] = 24\n",
    "    return row\n",
    "\n",
    "def change_date_format(df):\n",
    "    df['연월일'] = pd.to_datetime(df['연월일'])\n",
    "    df['시간'] = df['시간'].astype(int)\n",
    "    df = df.apply(change_dates_adversely, axis=1)\n",
    "    \n",
    "    del df['datetime']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "path = '/Users/younghun/Desktop/gitrepo/dacon_gas'\n",
    "gas_weather = merge_gas_weather(path)\n",
    "dataset = make_datetime_vars(gas_weather)\n",
    "dataset = extract_need_data(dataset)\n",
    "final_df = fe_autocorr_vars(dataset)\n",
    "final_df = change_date_format(final_df)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "print(final_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-crown",
   "metadata": {},
   "source": [
    "## 첫 번째 제출: 1년 전 변수까지만 포함해서\n",
    "- Train: 2014-01-01~\n",
    "- Train NMAE: \n",
    "- Valid NMAE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "anticipated-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터프레임: (383208, 9)\n",
      "Train: (368088, 9)\n",
      "Test: (15120, 9)\n",
      "데이터 개수 맞음\n"
     ]
    }
   ],
   "source": [
    "df = final_df.copy()\n",
    "print('총 데이터프레임:', df.shape)\n",
    "\n",
    "train = df[df['연월일'].dt.year < 2019]\n",
    "test = df[df['연월일'].dt.year >= 2019]\n",
    "print('Train:', train.shape)\n",
    "print('Test:', test.shape)\n",
    "\n",
    "if train.shape[0] + test.shape[0] == df.shape[0]:\n",
    "    print('데이터 개수 맞음')\n",
    "else:\n",
    "    print('데이터 개수 틀림')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "chinese-planner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Train: 2014년 부터 사용하고 01-01 ~ 03-31 기간만 추출\n",
    "train_cond1 = (train['연월일'].dt.year >= 2014)\n",
    "train_cond2 = (train['연월일'].dt.month >= 1) & (train['연월일'].dt.month <= 3)\n",
    "train = train[train_cond1]\n",
    "train = train[train_cond2]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dense-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '구분' 칼럼에 대하여 원-핫 인코딩 수행\n",
    "ohe_cols = ['B', 'C', 'D', 'E', 'G', 'H']\n",
    "\n",
    "train[ohe_cols] = pd.get_dummies(train['구분'], drop_first=True)\n",
    "test[ohe_cols] = pd.get_dummies(test['구분'], drop_first=True)\n",
    "\n",
    "\n",
    "# 칼럼 순서 배열 재배치\n",
    "cols_order = train.columns.tolist()\n",
    "cols_order.remove('공급량')\n",
    "cols_order.insert(len(cols_order), '공급량')\n",
    "\n",
    "train = train[cols_order]\n",
    "test = test[cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "recovered-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티인덱스 설정\n",
    "train = train.set_index(['연월일', '시간', '구분'])\n",
    "test = test.set_index(['연월일', '시간', '구분'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "generous-poetry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (60648, 12)\n",
      "Valid: (15120, 12)\n",
      "Train NMAE: 0.11323516981132432\n",
      "Valid NMAE: 0.16725128664449224\n"
     ]
    }
   ],
   "source": [
    "# 바로 모델링 진행 -> LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 마지막 2018-12-31 데이터 제외\n",
    "idx_level = train.index.get_level_values\n",
    "# Train/Valid 분할\n",
    "train_df = train[(idx_level(0) < '2018-01-01')]\n",
    "valid_df = train[(idx_level(0) >= '2018-01-01') & (idx_level(0) <= '2018-03-31')]\n",
    "print('Train:', train_df.shape)\n",
    "print('Valid:', valid_df.shape)\n",
    "\n",
    "\n",
    "# X, y 분할\n",
    "X_train, y_train = train_df.values[:, :-1], train_df['공급량']\n",
    "X_valid, y_valid = valid_df.values[:, :-1], valid_df['공급량']\n",
    "\n",
    "# model\n",
    "model = LGBMRegressor(n_estimators=100, min_child_samples=20)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "train_pred = model.predict(X_train)\n",
    "valid_pred = model.predict(X_valid)\n",
    "\n",
    "# evaluate\n",
    "train_NMAE = np.mean((np.abs(y_train-train_pred))/y_train)\n",
    "valid_NMAE = np.mean((np.abs(y_valid-valid_pred))/y_valid)\n",
    "\n",
    "print('Train NMAE:', train_NMAE)\n",
    "print('Valid NMAE:', valid_NMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "paperback-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pred shape: (15120,)\n"
     ]
    }
   ],
   "source": [
    "# Test 데이터에 대해 최종 예측\n",
    "\n",
    "X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "X_test = test.iloc[:, :-1].values\n",
    "\n",
    "# fit\n",
    "model = LGBMRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "test_pred = model.predict(X_test)\n",
    "print('test_pred shape:', test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "parallel-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['공급량'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "sacred-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv('/Users/younghun/Desktop/gitrepo/dacon_gas/submission/lgbm_base01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-print",
   "metadata": {},
   "source": [
    "## 두 번째 제출: 기상 데이터 ~2018-12-31년것까지 가져와서 사용 후 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "convinced-catholic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pymysql\n",
    "\n",
    "# time_delta = pd.Timestamp('2018-12-31') - pd.Timestamp('2013-01-01')\n",
    "# time_delta = time_delta.days + 1\n",
    "# max_pages = math.ceil((time_delta / 999) + 1)\n",
    "\n",
    "# for page in range(1, max_pages):\n",
    "#     # 서울 기상 데이터만 추출하는 예시\n",
    "#     key = 'j%2FJXmL%2BFxwnNYqN%2FyoLJSfJx3ioQV1HnmM9E7b%2FaGLjLv51g0vZSGQjk0UVyJmGZckzK7Cm8Jds6G42cqdkX0w%3D%3D'\n",
    "#     start_dt = '20130101'\n",
    "#     end_dt = '20181231'\n",
    "#     url = f'http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey={key}&numOfRows=999&pageNo={page}&dataCd=ASOS&dateCd=DAY&startDt={start_dt}&endDt={end_dt}&stnIds=108'\n",
    "    \n",
    "#     res = requests.get(url)\n",
    "#     soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "#     data_dict = {}\n",
    "    \n",
    "#     region, datetime = [], []\n",
    "#     avg_temp, min_temp = [], []\n",
    "#     max_temp, sum_rain = [], []\n",
    "#     avg_wind, avg_humid = [], []\n",
    "#     sum_gsr, ddmefs = [], []\n",
    "#     avg_ts = []\n",
    "    \n",
    "#     contents = soup.select('item')\n",
    "#     for content in contents:\n",
    "#         reg = content.select_one('stnnm').get_text()\n",
    "#         date = content.select_one('tm').get_text()\n",
    "#         avg_t = content.select_one('avgta').get_text()\n",
    "#         min_t = content.select_one('minta').get_text()\n",
    "#         max_t = content.select_one('maxta').get_text()\n",
    "#         sum_r = content.select_one('sumrn').get_text()\n",
    "#         avg_w = content.select_one('avgws').get_text()\n",
    "#         avg_h = content.select_one('avgrhm').get_text()\n",
    "#         sum_g = content.select_one('sumgsr').get_text()\n",
    "#         ddme = content.select_one('ddmefs').get_text()\n",
    "#         avg_s = content.select_one('avgts').get_text()\n",
    "        \n",
    "#         region.append(reg)\n",
    "#         datetime.append(date)\n",
    "#         avg_temp.append(avg_t)\n",
    "#         min_temp.append(min_t)\n",
    "#         max_temp.append(max_t)\n",
    "#         sum_rain.append(sum_r)\n",
    "#         avg_wind.append(avg_w)\n",
    "#         avg_humid.append(avg_h)\n",
    "#         sum_gsr.append(sum_g)\n",
    "#         ddmefs.append(ddme)\n",
    "#         avg_ts.append(avg_s)\n",
    "    \n",
    "#     data_dict['지역'] = region\n",
    "#     data_dict['시간'] = datetime\n",
    "#     data_dict['평균기온'] = avg_temp\n",
    "#     data_dict['최저기온'] = min_temp\n",
    "#     data_dict['최고기온'] = max_temp\n",
    "#     data_dict['합계강수량'] = sum_rain\n",
    "#     data_dict['평균풍속'] = avg_wind\n",
    "#     data_dict['평균습도'] = avg_humid\n",
    "#     data_dict['합계일사량'] = sum_gsr\n",
    "#     data_dict['신적설'] = ddmefs\n",
    "#     data_dict['평균지면온도'] = avg_ts   \n",
    "    \n",
    "#     db = pymysql.connect(host='localhost', port=3306, user='younghun', password='watson1259',\n",
    "#                         db='dacon_gas_weather_db', charset='utf8')\n",
    "#     cursor = db.cursor()\n",
    "#     rows = map(list, zip(*data_dict.values()))\n",
    "#     for row in rows:\n",
    "#         sql = \"\"\"INSERT INTO weather VALUES(\n",
    "#         '\"\"\"+row[0]+\"\"\"','\"\"\"+row[1]+\"\"\"','\"\"\"+row[2]+\"\"\"','\"\"\"+row[3]+\"\"\"','\"\"\"+row[4]+\"\"\"',\n",
    "#         '\"\"\"+row[5]+\"\"\"','\"\"\"+row[6]+\"\"\"','\"\"\"+row[7]+\"\"\"','\"\"\"+row[8]+\"\"\"','\"\"\"+row[9]+\"\"\"',\n",
    "#         '\"\"\"+row[10]+\"\"\"')\"\"\"\n",
    "#         cursor.execute(sql)\n",
    "#         db.commit()\n",
    "#     db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "needed-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터프레임: (383208, 18)\n",
      "Train: (368088, 18)\n",
      "Test: (15120, 18)\n",
      "데이터 개수 맞음\n"
     ]
    }
   ],
   "source": [
    "df = final_df.copy()\n",
    "print('총 데이터프레임:', df.shape)\n",
    "\n",
    "train = df[df['연월일'].dt.year < 2019]\n",
    "test = df[df['연월일'].dt.year >= 2019]\n",
    "print('Train:', train.shape)\n",
    "print('Test:', test.shape)\n",
    "\n",
    "if train.shape[0] + test.shape[0] == df.shape[0]:\n",
    "    print('데이터 개수 맞음')\n",
    "else:\n",
    "    print('데이터 개수 틀림')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "excited-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75768, 18)\n"
     ]
    }
   ],
   "source": [
    "# Train: 2014년 부터 사용하고 01-01 ~ 03-31 기간만 추출\n",
    "train_cond1 = (train['연월일'].dt.year >= 2014)\n",
    "train_cond2 = (train['연월일'].dt.month >= 1) & (train['연월일'].dt.month <= 3)\n",
    "train = train[train_cond1]\n",
    "train = train[train_cond2]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "guided-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '구분' 칼럼에 대하여 원-핫 인코딩 수행\n",
    "ohe_cols = ['B', 'C', 'D', 'E', 'G', 'H']\n",
    "\n",
    "train[ohe_cols] = pd.get_dummies(train['구분'], drop_first=True)\n",
    "test[ohe_cols] = pd.get_dummies(test['구분'], drop_first=True)\n",
    "\n",
    "\n",
    "# 칼럼 순서 배열 재배치\n",
    "cols_order = train.columns.tolist()\n",
    "cols_order.remove('공급량')\n",
    "cols_order.insert(len(cols_order), '공급량')\n",
    "\n",
    "train = train[cols_order]\n",
    "test = test[cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bulgarian-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티인덱스 설정\n",
    "train = train.set_index(['연월일', '시간', '구분'])\n",
    "test = test.set_index(['연월일', '시간', '구분'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "administrative-beverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (306768, 21)\n",
      "Valid: (15120, 21)\n",
      "Train NMAE: 0.8123844816204941\n",
      "Valid NMAE: 0.16915868159337155\n"
     ]
    }
   ],
   "source": [
    "# 바로 모델링 진행 -> LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 마지막 2018-12-31 데이터 제외\n",
    "idx_level = train.index.get_level_values\n",
    "# Train/Valid 분할\n",
    "train_df = train[(idx_level(0) < '2018-01-01')]\n",
    "valid_df = train[(idx_level(0) >= '2018-01-01') & (idx_level(0) <= '2018-03-31')]\n",
    "print('Train:', train_df.shape)\n",
    "print('Valid:', valid_df.shape)\n",
    "\n",
    "\n",
    "# X, y 분할\n",
    "X_train, y_train = train_df.values[:, :-1], train_df['공급량']\n",
    "X_valid, y_valid = valid_df.values[:, :-1], valid_df['공급량']\n",
    "\n",
    "# model\n",
    "model = LGBMRegressor(n_estimators=100, min_child_samples=20)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "train_pred = model.predict(X_train)\n",
    "valid_pred = model.predict(X_valid)\n",
    "\n",
    "# evaluate\n",
    "train_NMAE = np.mean((np.abs(y_train-train_pred))/y_train)\n",
    "valid_NMAE = np.mean((np.abs(y_valid-valid_pred))/y_valid)\n",
    "\n",
    "print('Train NMAE:', train_NMAE)\n",
    "print('Valid NMAE:', valid_NMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "known-pathology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120,)\n"
     ]
    }
   ],
   "source": [
    "# Test 데이터로 최종 예측\n",
    "X_train, y_train = train.values[:, :-1], train['공급량']\n",
    "X_test = test.values[:, :-1]\n",
    "\n",
    "model = LGBMRegressor(n_estimators=100, min_child_samples=20)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "test_pred = model.predict(X_test)\n",
    "print(test_pred.shape)  # 15,120개여야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "three-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv = pd.read_csv('/Users/younghun/Desktop/gitrepo/dacon_gas/sample_submission.csv')\n",
    "sample_csv['공급량'] = test_pred\n",
    "sample_csv.to_csv('/Users/younghun/Desktop/gitrepo/dacon_gas/submission/lgbm_base_weather(all_data).csv',\n",
    "                 index=False) # 모든 데이터로 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-creativity",
   "metadata": {},
   "source": [
    "## 버전 2 결론\n",
    "- 날씨 데이터 사용의 효과가 그닥.. -> 날씨 데이터 그만파자.. 오히려 빼는게 좋을 수도.. -> 자기상관변수 증감률 데이터 FE하기!\n",
    "- 모든 데이터를 다 사용했을 때가 Test 데이터에 대해 리더보드 결과는 더 좋음.. -> 모든 데이터 다 사용하기\n",
    "- 다른 모델들 사용 -> 여러가지 모델...뭘 사용할까!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-river",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
