{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alleged-cooking",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#현재-상태\" data-toc-modified-id=\"현재-상태-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>현재 상태</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-headline",
   "metadata": {},
   "source": [
    "### 현재 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "numeric-marine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383208, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "def get_NMAE(true, pred):\n",
    "    mae = np.abs(true-pred)/true\n",
    "    nmae = round(np.mean(mae), 3)\n",
    "    return nmae\n",
    "\n",
    "def load_datasets(path) -> pd.DataFrame:\n",
    "    train = pd.read_csv(os.path.join(path, '한국가스공사_시간별 공급량_20181231.csv'),\n",
    "                        encoding='cp949')\n",
    "    test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    # test 데이터 전처리\n",
    "    test['연월일'] = test['일자|시간|구분'].str.split(' ', expand=True)[0]\n",
    "    test['시간'] = test['일자|시간|구분'].str.split(' ', expand=True)[1].astype(int)\n",
    "    test['구분'] = test['일자|시간|구분'].str.split(' ', expand=True)[2]\n",
    "    del test['일자|시간|구분']\n",
    "\n",
    "    data = pd.concat([train, test], axis=0)\n",
    "    data['연월일'] = pd.to_datetime(data['연월일'])\n",
    "    return data\n",
    "\n",
    "def load_weather() -> pd.DataFrame:\n",
    "    db = pymysql.connect(host='localhost', port=3306, user='younghun', password='watson1259',\n",
    "                        db='dacon_gas_weather_db', charset='utf8')\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT datetime, avg_temp, min_temp, max_temp,\\\n",
    "              NULLIF(sum_rain, '') as sum_rain, avg_wind, avg_humid,\\\n",
    "              sum_gsr, NULLIF(ddmefs, '') as ddmefs, avg_ts \\\n",
    "              FROM weather ORDER BY datetime\"\n",
    "    \n",
    "    weather = pd.read_sql(sql, db)\n",
    "    weather = weather.fillna(0.)\n",
    "    \n",
    "    return weather\n",
    "    \n",
    "def merge_gas_weather(path):\n",
    "    gas = load_datasets(path)\n",
    "    weather = load_weather()\n",
    "    gas_weather = gas.merge(weather, how='left', left_on='연월일', right_on='datetime')\n",
    "    del gas_weather['datetime']\n",
    "    \n",
    "    return gas_weather\n",
    "\n",
    "def make_datetime_vars(data) -> pd.DataFrame:\n",
    "    data['year'] = data['연월일'].dt.year\n",
    "    data['month'] = data['연월일'].dt.month\n",
    "    data['day'] = data['연월일'].dt.day\n",
    "    #data['week_no'] = data['연월일'].dt.strftime(\"%V\").astype(int)\n",
    "    data['dayofweek'] = data['연월일'].dt.dayofweek\n",
    "    data['weekend_yn'] = np.where(data['dayofweek'].isin(['Saturday', 'Sunday']), 1, 0)\n",
    "    #data['dayofyear'] = data['연월일'].dt.dayofyear\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def change_dates(row):\n",
    "    if row['시간'] == 24:\n",
    "        row['연월일'] += pd.DateOffset(days=1)\n",
    "        row['시간'] = 0\n",
    "    return row\n",
    "\n",
    "\n",
    "def change_pandas_date_format(df):\n",
    "    \"\"\" 연월일 날짜 포맷 바꾸기\"\"\"\n",
    "    df = df.apply(change_dates, axis=1)\n",
    "    df['시간'] = df['시간'].apply(lambda x: str(x) if x >= 10 else '0' + str(x))\n",
    "    df['연월일'] = df['연월일'].astype(str)\n",
    "    df['datetime'] = df['연월일'] + ' ' + df['시간']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H')\n",
    "\n",
    "    df['prev_datetime'] = df['datetime'] - pd.DateOffset(years=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_autocorr_vars(df, gubun='A'):\n",
    "    sub_df = df[df['구분'] == gubun]\n",
    "    # 일년 전 그 시간대 공급량\n",
    "    sub_df['prev_year_공급량'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                          sub_df['datetime'].dt.hour])['공급량'].shift()\n",
    "#     # 이년 전 공급량 파생변수 생성\n",
    "#     sub_df['prev_two_year_공급량'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "#                                               sub_df['datetime'].dt.hour])['공급량'].shift(2)\n",
    "    #===============\n",
    "    #일년 전 평균 공급량\n",
    "    #===============\n",
    "    sub_df['prev_year'] = sub_df['prev_datetime'].dt.year\n",
    "    prev_year_mean_df = sub_df.groupby([sub_df['datetime'].dt.year])['공급량'].mean()\n",
    "    prev_year_mean_dict = dict(zip(prev_year_mean_df.index, prev_year_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_avg_공급량'] = sub_df['prev_year'].map(prev_year_mean_dict)\n",
    "    #====================\n",
    "    # 일년 전 월별 평균 공급량\n",
    "    #====================\n",
    "    prev_month_mean_df = sub_df.groupby([sub_df['datetime'].dt.year, sub_df['datetime'].dt.month])['공급량'].mean()\n",
    "    prev_month_mean_dict = dict(zip(prev_month_mean_df.index, prev_month_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_month'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                        sub_df['prev_datetime'].dt.month.values.reshape(-1, )))\n",
    "    sub_df['prev_month_avg_공급량'] = sub_df['prev_year_month'].map(prev_month_mean_dict)\n",
    "    #=======================\n",
    "    # 일년 전 월-일자별 평균 공급량\n",
    "    #=======================\n",
    "    prev_month_day_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                           sub_df['datetime'].dt.month,\n",
    "                                           sub_df['datetime'].dt.day])['공급량'].mean()\n",
    "    prev_month_day_mean_dict = dict(zip(prev_month_day_mean_df.index, prev_month_day_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_day'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.day.values.reshape(-1, )))\n",
    "    sub_df['prev_month_day_avg_공급량'] = sub_df['prev_year_month_day'].map(prev_month_day_mean_dict)\n",
    "    #========================\n",
    "    # 일년 전 월-시간 별 평균 공급량\n",
    "    #========================\n",
    "    prev_month_hour_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                            sub_df['datetime'].dt.month,\n",
    "                                            sub_df['datetime'].dt.hour])['공급량'].mean()\n",
    "    prev_month_hour_mean_dict = dict(zip(prev_month_hour_mean_df.index, prev_month_hour_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_hour'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.hour.values.reshape(-1, )))\n",
    "    sub_df['prev_month_hour_avg_공급량'] = sub_df['prev_year_month_hour'].map(prev_month_hour_mean_dict)\n",
    "    #==============\n",
    "    # 증가율 변수 생성\n",
    "    #==============\n",
    "    sub_df['prev_year_ratio'] = (sub_df['prev_year_공급량']-sub_df['prev_year_avg_공급량'])/sub_df['prev_year_avg_공급량']\n",
    "    sub_df['prev_month_ratio'] = (sub_df['prev_year_공급량']-sub_df['prev_month_avg_공급량'])/sub_df['prev_month_avg_공급량']\n",
    "    sub_df['prev_month_day_ratio'] = (sub_df['prev_year_공급량']-sub_df['prev_month_day_avg_공급량'])/sub_df['prev_month_day_avg_공급량']\n",
    "    sub_df['prev_month_hour_ratio'] = (sub_df['prev_year_공급량']-sub_df['prev_month_hour_avg_공급량'])/sub_df['prev_month_hour_avg_공급량']\n",
    "    #========================\n",
    "    # 일년 전 그 날의 기상 변수 FE\n",
    "    #========================\n",
    "    weather_cols = ['avg_temp','min_temp','max_temp','sum_rain','avg_wind','avg_humid','sum_gsr','ddmefs','avg_ts']\n",
    "    for col in weather_cols:\n",
    "        sub_df[f'prev_year_{col}'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                                  sub_df['datetime'].dt.hour])[col].shift()\n",
    "        sub_df[f'prev_year_{col}'] = pd.to_numeric(sub_df[f'prev_year_{col}'], downcast=\"float\")\n",
    "    #================\n",
    "    # 필요한 칼럼들만 추출\n",
    "    #================\n",
    "    used_cols = ['연월일', '시간', '구분', 'datetime',\n",
    "#                  'year', 'month', 'day', 'week_no','dayofweek','weekend_yn',\n",
    "                 'prev_year_공급량', 'prev_year_avg_공급량','prev_month_avg_공급량', 'prev_month_day_avg_공급량', 'prev_month_hour_avg_공급량',\n",
    "                 'prev_year_ratio','prev_month_ratio','prev_month_day_ratio','prev_month_hour_ratio']\n",
    "    #weather_cols = [f'prev_year_{col}' for col in weather_cols]\n",
    "    #used_cols += weather_cols + ['공급량']\n",
    "    used_cols += ['공급량']\n",
    "    sub_df = sub_df[used_cols]\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def fe_autocorr_vars(df):\n",
    "    final_df = pd.DataFrame()\n",
    "    gubun_cols = ['A','B','C','D','E','G','H']\n",
    "    for gubun in tqdm(gubun_cols):\n",
    "        sub_df = make_autocorr_vars(df, gubun=gubun)\n",
    "        final_df = pd.concat([final_df, sub_df], axis=0)\n",
    "    # 제거할 칼럼들\n",
    "    final_df = final_df.drop(['prev_year_avg_공급량', 'prev_month_hour_ratio'], axis=1)\n",
    "    return final_df\n",
    "\n",
    "def change_dates_adversely(row):\n",
    "    if row['datetime'].hour == 0:\n",
    "        row['연월일'] -= pd.DateOffset(days=1)\n",
    "        row['시간'] = 24\n",
    "    return row\n",
    "\n",
    "def change_date_format(df):\n",
    "    df['연월일'] = pd.to_datetime(df['연월일'])\n",
    "    df['시간'] = df['시간'].astype(int)\n",
    "    df = df.apply(change_dates_adversely, axis=1)\n",
    "    \n",
    "    del df['datetime']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 추가 FE 하는 함수 -> 2018년까지의 평균값을 2019년에 집어넣어야 함!\n",
    "def fe_avg_vars(final_df):\n",
    "    main_df = pd.DataFrame()\n",
    "    cols = ['A', 'B', 'C', 'D', 'E', 'G', 'H']\n",
    "    for gubun in tqdm(cols):\n",
    "        sub_df = final_df[final_df['구분'] == gubun]\n",
    "        ## 단, FE 계산 때는 2018년까지의 Train 데이터만 사용, FE 적용은 Train, Test 모두에 적용\n",
    "        #===============\n",
    "        # 1.월별 평균 공급량\n",
    "        #===============\n",
    "        fe_df = sub_df[sub_df['연월일'].dt.year < 2019]\n",
    "        group = fe_df.groupby([fe_df['연월일'].dt.month]).agg({'공급량':'mean'}) # Train만 사용\n",
    "        month_avg_dict = dict(zip(group.index, group.values.reshape(-1,)))\n",
    "        sub_df['month_avg'] = sub_df['연월일'].dt.month.map(month_avg_dict)    # Train, Test에 모두 적용\n",
    "        #==================\n",
    "        # 2. 월-일별 평균 공급량\n",
    "        #==================\n",
    "        group = fe_df.groupby([fe_df['연월일'].dt.month, fe_df['연월일'].dt.day]).agg({'공급량':'mean'})\n",
    "        group_dict1 = dict(zip(group.index, group.values.reshape(-1,)))\n",
    "        # 임시 변수 생성\n",
    "        sub_df['month-day_tuple'] = tuple(zip(sub_df['연월일'].dt.month.values.reshape(-1,),\n",
    "                                              sub_df['연월일'].dt.day.values.reshape(-1,)))\n",
    "        # 임시 변수 기반으로 group_dict 매핑\n",
    "        sub_df['month_day_avg'] = sub_df['month-day_tuple'].map(group_dict1)\n",
    "        del sub_df['month-day_tuple']\n",
    "        #======================\n",
    "        # 3. 월-일-시간별 평균 공급량\n",
    "        #======================\n",
    "        group = fe_df.groupby([fe_df['연월일'].dt.month, fe_df['연월일'].dt.day, fe_df['시간']])\\\n",
    "                     .agg({'공급량': 'mean'})\n",
    "        group_dict2 = dict(zip(group.index, group.values.reshape(-1,)))\n",
    "        # 임시 변수 생성\n",
    "        sub_df['month-day-hr_tuple'] = tuple(zip(sub_df['연월일'].dt.month.values.reshape(-1,),\n",
    "                                                  sub_df['연월일'].dt.day.values.reshape(-1,),\n",
    "                                                  sub_df['시간'].values.reshape(-1,)))\n",
    "        # 임시 변수 기반으로 group_dict 매핑\n",
    "        sub_df['month_day_hr_avg'] = sub_df['month-day-hr_tuple'].map(group_dict2)\n",
    "        del sub_df['month-day-hr_tuple']\n",
    "        #=========================================\n",
    "        # 3. 월별 평균 공급량 대비 월-일별 평균 공급량 증감률\n",
    "        #=========================================\n",
    "        sub_df['month_month-day_ratio'] = (sub_df['month_day_avg']-sub_df['month_avg'])/sub_df['month_avg']\n",
    "        #=============================================\n",
    "        # 4. 월별 평균 공급량 대비 월-일-시간별 평균 공급량 증감률\n",
    "        #=============================================\n",
    "        sub_df['month_month-day-hr_ratio'] = (sub_df['month_day_hr_avg']-sub_df['month_avg'])/sub_df['month_avg']\n",
    "        #===============================================\n",
    "        # 5. 월-일별 평균 공급량 대비 월-일-시간별 평균 공급량 증감률\n",
    "        #===============================================\n",
    "        sub_df['month-day_month-day-hr_ratio'] = (sub_df['month_day_hr_avg']-sub_df['month_day_avg'])/sub_df['month_day_avg']\n",
    "        \n",
    "        \n",
    "        # sub_df를 main_df에 결합\n",
    "        main_df = pd.concat([main_df, sub_df], axis=0)\n",
    "    \n",
    "    # 칼럼 순서 맞추기\n",
    "    cols_order = main_df.columns.tolist()\n",
    "    cols_order.remove('공급량')\n",
    "    cols_order.insert(len(cols_order), '공급량')\n",
    "    main_df = main_df[cols_order]\n",
    "        \n",
    "    return main_df\n",
    "\n",
    "\n",
    "path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas'\n",
    "gas_weather = merge_gas_weather(path)\n",
    "dataset = make_datetime_vars(gas_weather)\n",
    "dataset = change_pandas_date_format(dataset)\n",
    "dataset = fe_autocorr_vars(dataset)\n",
    "dataset = change_date_format(dataset)\n",
    "final_df = fe_avg_vars(dataset)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "print(final_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "hairy-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scaling_ftr(final_df, model, submission_csv):\n",
    "    cols = ['A', 'B', 'C', 'D', 'E', 'G', 'H']\n",
    "    all_pred = np.array([])\n",
    "    for gubun in cols:\n",
    "        sub_df = final_df[final_df['구분'] == gubun]\n",
    "        sub_df = sub_df.set_index(['연월일', '시간', '구분'])\n",
    "        idx_level = sub_df.index.get_level_values\n",
    "        \n",
    "        train = sub_df[(idx_level(0) < '2018-09-01')].fillna(method='ffill')\n",
    "        valid = sub_df[(idx_level(0) >= '2018-09-01')&(idx_level(0) <= '2018-12-31')].fillna(method='ffill')\n",
    "        \n",
    "        X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "        X_valid, y_valid = valid.iloc[:, :-1].values, valid['공급량']\n",
    "        # Scaling feature\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "        # fit model\n",
    "        #model = model_dict[gubun]\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict\n",
    "        train_pred = model.predict(X_train)\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        # evaluate\n",
    "        train_NMAE = get_NMAE(y_train, train_pred)\n",
    "        valid_NMAE = get_NMAE(y_valid, valid_pred)\n",
    "        print(f'# 유형({gubun}) - Train NMAE: {train_NMAE: .4f}')\n",
    "        print(f'# 유형({gubun}) - Valid NMAE: {valid_NMAE: .4f}')\n",
    "        print()\n",
    "        \n",
    "        # 다시 Train, Test로 분할\n",
    "        train = sub_df[(idx_level(0) < '2019-01-01')].fillna(method='ffill')\n",
    "        test = sub_df[(idx_level(0) >= '2019-01-01')].fillna(method='ffill')\n",
    "        \n",
    "        X_train, y_train = train.iloc[:, :-1].values, train['공급량']\n",
    "        X_test = test.iloc[:, :-1].values\n",
    "        # Scaling\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # fit model\n",
    "        #model = model_dict[gubun]\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict\n",
    "        test_pred = model.predict(X_test)\n",
    "        all_pred = np.append(all_pred, test_pred)\n",
    "    submission_csv['공급량'] = all_pred\n",
    "    return submission_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "certified-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(A) - Train NMAE:  0.1000\n",
      "# 유형(A) - Valid NMAE:  0.1400\n",
      "\n",
      "[14:44:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:44:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(B) - Train NMAE:  0.1050\n",
      "# 유형(B) - Valid NMAE:  0.1410\n",
      "\n",
      "[14:44:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:44:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(C) - Train NMAE:  0.9540\n",
      "# 유형(C) - Valid NMAE:  0.2610\n",
      "\n",
      "[14:44:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:44:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(D) - Train NMAE:  0.0990\n",
      "# 유형(D) - Valid NMAE:  0.1500\n",
      "\n",
      "[14:44:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:44:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(E) - Train NMAE:  0.0890\n",
      "# 유형(E) - Valid NMAE:  0.1440\n",
      "\n",
      "[14:44:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:45:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(G) - Train NMAE:  0.1030\n",
      "# 유형(G) - Valid NMAE:  0.1470\n",
      "\n",
      "[14:45:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:45:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# 유형(H) - Train NMAE:  0.1000\n",
      "# 유형(H) - Valid NMAE:  0.1290\n",
      "\n",
      "[14:45:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# model\n",
    "lgbm_reg = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "xgb_reg = XGBRegressor(n_estimators=100, random_state=42)\n",
    "hybrid_reg = VotingRegressor([('lgbm', lgbm_reg), ('xgb', xgb_reg)])\n",
    "\n",
    "# submission csv\n",
    "dirname = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas'\n",
    "sub_csv = pd.read_csv(os.path.join(dirname, 'sample_submission.csv'))\n",
    "\n",
    "# predict\n",
    "pred_csv = predict_scaling_ftr(final_df=final_df, model=hybrid_reg, submission_csv=sub_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "mature-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C유형에 대해 Prophet으로 예측\n",
    "# C 유형에 대해서 Prophet으로 예측해보기\n",
    "df = final_df.copy()\n",
    "c_df = df[df['구분'] == 'C']\n",
    "\n",
    "def date_format_pandas(row):\n",
    "    if row['시간'] == 24:\n",
    "        row['연월일'] += pd.DateOffset(days=1)\n",
    "        row['시간'] = 0\n",
    "    return row\n",
    "\n",
    "c_df = c_df.apply(date_format_pandas, axis=1)\n",
    "c_df['시간'] = c_df['시간'].apply(lambda x: str(x) if x >= 10 else '0'+str(x))\n",
    "c_df['연월일'] = c_df['연월일'].astype(str)\n",
    "c_df['time'] = c_df['연월일'] + ' ' + c_df['시간']\n",
    "c_df['time'] = pd.to_datetime(c_df['time'], format='%Y-%m-%d %H')\n",
    "\n",
    "# 일변량으로 Kats Prophet 사용\n",
    "from kats.consts import TimeSeriesData\n",
    "from kats.models.prophet import ProphetModel, ProphetParams\n",
    "\n",
    "# Train, Valid 분할\n",
    "c_train = c_df[c_df['time'] <= '2019-01-01 00:00:00']\n",
    "c_test = c_df[(c_df['time'] > '2019-01-01 00:00:00')]\n",
    "\n",
    "uni_c_df = c_train[['time', '공급량']]\n",
    "uni_c_ts = TimeSeriesData(uni_c_df)\n",
    "\n",
    "# params\n",
    "params = ProphetParams(seasonality_mode='additive')\n",
    "# model\n",
    "prophet = ProphetModel(uni_c_ts, params=params)\n",
    "# fit\n",
    "prophet.fit()\n",
    "# predict\n",
    "test_pred = prophet.predict(steps=c_test.shape[0], freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "vulnerable-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pred shape: (2160, 4)\n"
     ]
    }
   ],
   "source": [
    "# 일변량으로 Kats Prophet 사용\n",
    "from kats.consts import TimeSeriesData\n",
    "from kats.models.prophet import ProphetModel, ProphetParams\n",
    "\n",
    "def date_format_pandas(row):\n",
    "    if row['시간'] == 24:\n",
    "        row['연월일'] += pd.DateOffset(days=1)\n",
    "        row['시간'] = 0\n",
    "    return row\n",
    "\n",
    "def prophet(final_df, gubun):\n",
    "    gubun_df = final_df[final_df['구분'] == gubun]\n",
    "    gubun_df = gubun_df.apply(date_format_pandas, axis=1)\n",
    "    gubun_df['시간'] = gubun_df['시간'].apply(lambda x: str(x) if x >= 10 else '0'+str(x))\n",
    "    gubun_df['연월일'] = gubun_df['연월일'].astype(str)\n",
    "    gubun_df['time'] = gubun_df['연월일'] + ' ' + gubun_df['시간']\n",
    "    gubun_df['time'] = pd.to_datetime(gubun_df['time'], format='%Y-%m-%d %H')\n",
    "    \n",
    "    # Train, Valid 분할\n",
    "    train = gubun_df[gubun_df['time'] <= '2019-01-01 00:00:00']\n",
    "    test = gubun_df[(gubun_df['time'] > '2019-01-01 00:00:00')]\n",
    "    # TimeSeries 객체로 변환\n",
    "    uni_df = train[['time', '공급량']]\n",
    "    uni_ts = TimeSeriesData(uni_df)\n",
    "    # params\n",
    "    params = ProphetParams(seasonality_mode='additive')\n",
    "    # model\n",
    "    prophet = ProphetModel(uni_ts, params=params)\n",
    "    # fit\n",
    "    prophet.fit()\n",
    "    # predict\n",
    "    test_pred = prophet.predict(steps=test.shape[0], freq='H')\n",
    "    print('test_pred shape:', test_pred.shape)\n",
    "    return test_pred\n",
    "\n",
    "def merge_pred_csv_prophet_csv(final_df, pred_csv, gubun='C'):\n",
    "    \"\"\"\n",
    "    pred_csv : 일반 머신러닝 모델로 예측한 Test 데이터 결과값이 담긴 panadas.dataframe\n",
    "    test_pred : Prophet으로 특정 유형에 대해 예측한 결과값이 담긴 panadas.dataframe\n",
    "    \"\"\"\n",
    "    test_pred = prophet(final_df, gubun)\n",
    "    \n",
    "    pred_csv['일자'] = pred_csv['일자|시간|구분'].str.split(' ', expand=True)[0]\n",
    "    pred_csv['시간'] = pred_csv['일자|시간|구분'].str.split(' ', expand=True)[1]\n",
    "    pred_csv['구분'] = pred_csv['일자|시간|구분'].str.split(' ', expand=True)[2]\n",
    "    pred_csv['일자'] = pd.to_datetime(pred_csv['일자'])\n",
    "    pred_csv['시간'] = pred_csv['시간'].astype(int)\n",
    "    \n",
    "    final_csv = pred_csv[pred_csv['구분'] != gubun]\n",
    "    gubun_csv = pred_csv[pred_csv['구분'] == gubun]\n",
    "    gubun_csv['공급량'] = test_pred['fcst'].values\n",
    "    final_csv = pd.concat([final_csv, gubun_csv], axis=0)\n",
    "    columns = ['구분', '일자', '시간']\n",
    "    final_csv = final_csv.sort_values(by=columns)\n",
    "    final_csv = final_csv.drop(columns, axis=1)\n",
    "    return final_csv\n",
    "\n",
    "\n",
    "sub_csv = merge_pred_csv_prophet_csv(final_df=final_df, pred_csv=pred_csv, gubun='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "secret-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'submission/0103False_SimulFalse_xgb+lgbm_cols-autocorr_extra_vars_MinMaxscale_exclude_datetime_C_prophet.csv'\n",
    "sub_csv.to_csv(os.path.join(dirname, save_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-oakland",
   "metadata": {},
   "source": [
    "- 오버피팅 발생... -> 차원의 수를 줄여야 할 듯 싶다..\n",
    "- PLS, PCA 활용해서 차원 감소 후 시도\n",
    "- 딥러닝 시도\n",
    "    - MLPRegressor\n",
    "    - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-filling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
