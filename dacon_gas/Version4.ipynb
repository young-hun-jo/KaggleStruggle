{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "paperback-concrete",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#í˜„ì¬-ìƒíƒœ\" data-toc-modified-id=\"í˜„ì¬-ìƒíƒœ-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>í˜„ì¬ ìƒíƒœ</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stacking(1)\" data-toc-modified-id=\"Stacking(1)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Stacking(1)</a></span></li><li><span><a href=\"#Stacking(2)\" data-toc-modified-id=\"Stacking(2)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Stacking(2)</a></span></li><li><span><a href=\"#í˜„ì¬ìƒíƒœ-+-Cìœ í˜•ë§Œ-ë”°ë¡œ-Prophetìœ¼ë¡œ-ì˜ˆì¸¡\" data-toc-modified-id=\"í˜„ì¬ìƒíƒœ-+-Cìœ í˜•ë§Œ-ë”°ë¡œ-Prophetìœ¼ë¡œ-ì˜ˆì¸¡-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>í˜„ì¬ìƒíƒœ + Cìœ í˜•ë§Œ ë”°ë¡œ Prophetìœ¼ë¡œ ì˜ˆì¸¡</a></span></li><li><span><a href=\"#Stacking(3)-+-C-ìœ í˜•ì€-Prophetìœ¼ë¡œ\" data-toc-modified-id=\"Stacking(3)-+-C-ìœ í˜•ì€-Prophetìœ¼ë¡œ-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Stacking(3) + C ìœ í˜•ì€ Prophetìœ¼ë¡œ</a></span></li><li><span><a href=\"#ë‹¤ì‹œ-ìê¸°ìƒê´€-ë³€ìˆ˜-FEìœ¼ë¡œ-ëŒì•„ê°€ê¸°-+-êµ¬ë¶„-ìœ í˜•-ë³„ë¡œ-ë”°ë¡œ-ëª¨ë¸-ë§Œë“¤ê¸°\" data-toc-modified-id=\"ë‹¤ì‹œ-ìê¸°ìƒê´€-ë³€ìˆ˜-FEìœ¼ë¡œ-ëŒì•„ê°€ê¸°-+-êµ¬ë¶„-ìœ í˜•-ë³„ë¡œ-ë”°ë¡œ-ëª¨ë¸-ë§Œë“¤ê¸°-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>ë‹¤ì‹œ ìê¸°ìƒê´€ ë³€ìˆ˜ FEìœ¼ë¡œ ëŒì•„ê°€ê¸° + êµ¬ë¶„ ìœ í˜• ë³„ë¡œ ë”°ë¡œ ëª¨ë¸ ë§Œë“¤ê¸°</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383208, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "def load_datasets(path) -> pd.DataFrame:\n",
    "    train = pd.read_csv(os.path.join(path, 'í•œêµ­ê°€ìŠ¤ê³µì‚¬_ì‹œê°„ë³„ ê³µê¸‰ëŸ‰_20181231.csv'),\n",
    "                        encoding='cp949')\n",
    "    test = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    # test ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    test['ì—°ì›”ì¼'] = test['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[0]\n",
    "    test['ì‹œê°„'] = test['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[1].astype(int)\n",
    "    test['êµ¬ë¶„'] = test['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[2]\n",
    "    del test['ì¼ì|ì‹œê°„|êµ¬ë¶„']\n",
    "\n",
    "    data = pd.concat([train, test], axis=0)\n",
    "    data['ì—°ì›”ì¼'] = pd.to_datetime(data['ì—°ì›”ì¼'])\n",
    "    return data\n",
    "\n",
    "def load_weather() -> pd.DataFrame:\n",
    "    db = pymysql.connect(host='localhost', port=3306, user='younghun', password='watson1259',\n",
    "                        db='dacon_gas_weather_db', charset='utf8')\n",
    "    cursor = db.cursor()\n",
    "    sql = \"SELECT datetime, avg_temp, min_temp, max_temp,\\\n",
    "              NULLIF(sum_rain, '') as sum_rain, avg_wind, avg_humid,\\\n",
    "              sum_gsr, NULLIF(ddmefs, '') as ddmefs, avg_ts \\\n",
    "              FROM weather ORDER BY datetime\"\n",
    "    \n",
    "    weather = pd.read_sql(sql, db)\n",
    "    weather = weather.fillna(0.)\n",
    "    \n",
    "    return weather\n",
    "    \n",
    "def merge_gas_weather(path):\n",
    "    gas = load_datasets(path)\n",
    "    weather = load_weather()\n",
    "    gas_weather = gas.merge(weather, how='left', left_on='ì—°ì›”ì¼', right_on='datetime')\n",
    "    del gas_weather['datetime']\n",
    "    \n",
    "    return gas_weather\n",
    "\n",
    "def make_datetime_vars(data) -> pd.DataFrame:\n",
    "    data['year'] = data['ì—°ì›”ì¼'].dt.year\n",
    "    data['month'] = data['ì—°ì›”ì¼'].dt.month\n",
    "    data['day'] = data['ì—°ì›”ì¼'].dt.day\n",
    "    data['week_no'] = data['ì—°ì›”ì¼'].dt.strftime(\"%V\").astype(int)\n",
    "    data['dayofweek'] = data['ì—°ì›”ì¼'].dt.dayofweek\n",
    "    data['weekend_yn'] = np.where(data['dayofweek'].isin(['Saturday', 'Sunday']), 1, 0)\n",
    "    data['dayofyear'] = data['ì—°ì›”ì¼'].dt.dayofyear\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def change_dates(row):\n",
    "    if row['ì‹œê°„'] == 24:\n",
    "        row['ì—°ì›”ì¼'] += pd.DateOffset(days=1)\n",
    "        row['ì‹œê°„'] = 0\n",
    "    return row\n",
    "\n",
    "\n",
    "def change_pandas_date_format(df):\n",
    "    \"\"\" ì—°ì›”ì¼ ë‚ ì§œ í¬ë§· ë°”ê¾¸ê¸°\"\"\"\n",
    "    df = df.apply(change_dates, axis=1)\n",
    "    df['ì‹œê°„'] = df['ì‹œê°„'].apply(lambda x: str(x) if x >= 10 else '0' + str(x))\n",
    "    df['ì—°ì›”ì¼'] = df['ì—°ì›”ì¼'].astype(str)\n",
    "    df['datetime'] = df['ì—°ì›”ì¼'] + ' ' + df['ì‹œê°„']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H')\n",
    "\n",
    "    df['prev_datetime'] = df['datetime'] - pd.DateOffset(years=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_autocorr_vars(df, gubun='A'):\n",
    "    sub_df = df[df['êµ¬ë¶„'] == gubun]\n",
    "    # ì¼ë…„ ì „ ê·¸ ì‹œê°„ëŒ€ ê³µê¸‰ëŸ‰\n",
    "    sub_df['prev_year_ê³µê¸‰ëŸ‰'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                          sub_df['datetime'].dt.hour])['ê³µê¸‰ëŸ‰'].shift()\n",
    "#     # ì´ë…„ ì „ ê³µê¸‰ëŸ‰ íŒŒìƒë³€ìˆ˜ ìƒì„±\n",
    "#     sub_df['prev_two_year_ê³µê¸‰ëŸ‰'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "#                                               sub_df['datetime'].dt.hour])['ê³µê¸‰ëŸ‰'].shift(2)\n",
    "    #===============\n",
    "    #ì¼ë…„ ì „ í‰ê·  ê³µê¸‰ëŸ‰\n",
    "    #===============\n",
    "    sub_df['prev_year'] = sub_df['prev_datetime'].dt.year\n",
    "    prev_year_mean_df = sub_df.groupby([sub_df['datetime'].dt.year])['ê³µê¸‰ëŸ‰'].mean()\n",
    "    prev_year_mean_dict = dict(zip(prev_year_mean_df.index, prev_year_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_avg_ê³µê¸‰ëŸ‰'] = sub_df['prev_year'].map(prev_year_mean_dict)\n",
    "    #====================\n",
    "    # ì¼ë…„ ì „ ì›”ë³„ í‰ê·  ê³µê¸‰ëŸ‰\n",
    "    #====================\n",
    "    prev_month_mean_df = sub_df.groupby([sub_df['datetime'].dt.year, sub_df['datetime'].dt.month])['ê³µê¸‰ëŸ‰'].mean()\n",
    "    prev_month_mean_dict = dict(zip(prev_month_mean_df.index, prev_month_mean_df.values.reshape(-1, )))\n",
    "    sub_df['prev_year_month'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                        sub_df['prev_datetime'].dt.month.values.reshape(-1, )))\n",
    "    sub_df['prev_month_avg_ê³µê¸‰ëŸ‰'] = sub_df['prev_year_month'].map(prev_month_mean_dict)\n",
    "    #=======================\n",
    "    # ì¼ë…„ ì „ ì›”-ì¼ìë³„ í‰ê·  ê³µê¸‰ëŸ‰\n",
    "    #=======================\n",
    "    prev_month_day_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                           sub_df['datetime'].dt.month,\n",
    "                                           sub_df['datetime'].dt.day])['ê³µê¸‰ëŸ‰'].mean()\n",
    "    prev_month_day_mean_dict = dict(zip(prev_month_day_mean_df.index, prev_month_day_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_day'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                            sub_df['prev_datetime'].dt.day.values.reshape(-1, )))\n",
    "    sub_df['prev_month_day_avg_ê³µê¸‰ëŸ‰'] = sub_df['prev_year_month_day'].map(prev_month_day_mean_dict)\n",
    "    #========================\n",
    "    # ì¼ë…„ ì „ ì›”-ì‹œê°„ ë³„ í‰ê·  ê³µê¸‰ëŸ‰\n",
    "    #========================\n",
    "    prev_month_hour_mean_df = sub_df.groupby([sub_df['datetime'].dt.year,\n",
    "                                            sub_df['datetime'].dt.month,\n",
    "                                            sub_df['datetime'].dt.hour])['ê³µê¸‰ëŸ‰'].mean()\n",
    "    prev_month_hour_mean_dict = dict(zip(prev_month_hour_mean_df.index, prev_month_hour_mean_df.values.reshape(-1, )))\n",
    "\n",
    "    sub_df['prev_year_month_hour'] = tuple(zip(sub_df['prev_year'].values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.month.values.reshape(-1, ),\n",
    "                                             sub_df['prev_datetime'].dt.hour.values.reshape(-1, )))\n",
    "    sub_df['prev_month_hour_avg_ê³µê¸‰ëŸ‰'] = sub_df['prev_year_month_hour'].map(prev_month_hour_mean_dict)\n",
    "    #==============\n",
    "    # ì¦ê°€ìœ¨ ë³€ìˆ˜ ìƒì„±\n",
    "    #==============\n",
    "    sub_df['prev_year_ratio'] = (sub_df['prev_year_ê³µê¸‰ëŸ‰']-sub_df['prev_year_avg_ê³µê¸‰ëŸ‰'])/sub_df['prev_year_avg_ê³µê¸‰ëŸ‰']\n",
    "    sub_df['prev_month_ratio'] = (sub_df['prev_year_ê³µê¸‰ëŸ‰']-sub_df['prev_month_avg_ê³µê¸‰ëŸ‰'])/sub_df['prev_month_avg_ê³µê¸‰ëŸ‰']\n",
    "    sub_df['prev_month_day_ratio'] = (sub_df['prev_year_ê³µê¸‰ëŸ‰']-sub_df['prev_month_day_avg_ê³µê¸‰ëŸ‰'])/sub_df['prev_month_day_avg_ê³µê¸‰ëŸ‰']\n",
    "    sub_df['prev_month_hour_ratio'] = (sub_df['prev_year_ê³µê¸‰ëŸ‰']-sub_df['prev_month_hour_avg_ê³µê¸‰ëŸ‰'])/sub_df['prev_month_hour_avg_ê³µê¸‰ëŸ‰']\n",
    "    #========================\n",
    "    # ì¼ë…„ ì „ ê·¸ ë‚ ì˜ ê¸°ìƒ ë³€ìˆ˜ FE\n",
    "    #========================\n",
    "    weather_cols = ['avg_temp','min_temp','max_temp','sum_rain','avg_wind','avg_humid','sum_gsr','ddmefs','avg_ts']\n",
    "    for col in weather_cols:\n",
    "        sub_df[f'prev_year_{col}'] = sub_df.groupby([sub_df['datetime'].dt.month, sub_df['datetime'].dt.day,\n",
    "                                                  sub_df['datetime'].dt.hour])[col].shift()\n",
    "        sub_df[f'prev_year_{col}'] = pd.to_numeric(sub_df[f'prev_year_{col}'], downcast=\"float\")\n",
    "    #================\n",
    "    # í•„ìš”í•œ ì¹¼ëŸ¼ë“¤ë§Œ ì¶”ì¶œ\n",
    "    #================\n",
    "    used_cols = ['ì—°ì›”ì¼', 'ì‹œê°„', 'êµ¬ë¶„', 'datetime',\n",
    "                 #'year', 'month', 'day', 'week_no','dayofweek','weekend_yn','dayofyear',\n",
    "                 'prev_year_ê³µê¸‰ëŸ‰', 'prev_year_avg_ê³µê¸‰ëŸ‰','prev_month_avg_ê³µê¸‰ëŸ‰', 'prev_month_day_avg_ê³µê¸‰ëŸ‰', 'prev_month_hour_avg_ê³µê¸‰ëŸ‰',\n",
    "                 'prev_year_ratio','prev_month_ratio','prev_month_day_ratio','prev_month_hour_ratio']\n",
    "    #weather_cols = [f'prev_year_{col}' for col in weather_cols]\n",
    "    #used_cols += weather_cols + ['ê³µê¸‰ëŸ‰']\n",
    "    used_cols += ['ê³µê¸‰ëŸ‰']\n",
    "    sub_df = sub_df[used_cols]\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def fe_autocorr_vars(df):\n",
    "    final_df = pd.DataFrame()\n",
    "    gubun_cols = ['A','B','C','D','E','G','H']\n",
    "    for gubun in tqdm(gubun_cols):\n",
    "        sub_df = make_autocorr_vars(df, gubun=gubun)\n",
    "        final_df = pd.concat([final_df, sub_df], axis=0)\n",
    "    return final_df\n",
    "\n",
    "def change_dates_adversely(row):\n",
    "    if row['datetime'].hour == 0:\n",
    "        row['ì—°ì›”ì¼'] -= pd.DateOffset(days=1)\n",
    "        row['ì‹œê°„'] = 24\n",
    "    return row\n",
    "\n",
    "def change_date_format(df):\n",
    "    df['ì—°ì›”ì¼'] = pd.to_datetime(df['ì—°ì›”ì¼'])\n",
    "    df['ì‹œê°„'] = df['ì‹œê°„'].astype(int)\n",
    "    df = df.apply(change_dates_adversely, axis=1)\n",
    "    \n",
    "    del df['datetime']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas'\n",
    "gas_weather = merge_gas_weather(path)\n",
    "dataset = make_datetime_vars(gas_weather)\n",
    "dataset = change_pandas_date_format(dataset)\n",
    "final_df = fe_autocorr_vars(dataset)\n",
    "final_df = change_date_format(final_df)\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "print(final_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "detected-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014ë…„ë¶€í„° ë°ì´í„° ì¶”ì¶œí•˜ëŠ”ë°, ë§¤ë³€ 01-03ì›”ë§Œ ì‚¬ìš©í• ì§€, ì „ì²´ ì‚¬ìš©í• ì§€ í•¨ìˆ˜\n",
    "def extract_dataset(final_df, split=False):\n",
    "    # 2014-01-01ë¶€í„° ì‚¬ìš©\n",
    "    cond = final_df['ì—°ì›”ì¼'].dt.year >= 2014\n",
    "    final_df = final_df[cond]\n",
    "    if split:\n",
    "        cond0103 = (final_df['ì—°ì›”ì¼'].dt.month >= 1) & (final_df['ì—°ì›”ì¼'].dt.month <= 3)\n",
    "        final_df = final_df[cond0103]\n",
    "        return final_df\n",
    "    else:\n",
    "        return final_df\n",
    "    \n",
    "# êµ¬ë¶„ ì—†ì´ í†µí•© ì˜ˆì¸¡ or êµ¬ë¶„ ìœ í˜•ëŒ€ë¡œ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ë°ì´í„° í¬ë§· í˜•íƒœ\n",
    "def predict_simultaneously(final_df, simultaneously=False):\n",
    "    if simultaneously:\n",
    "        # êµ¬ë¶„ ì›-í•« ì¸ì½”ë”©\n",
    "        final_df[['B','C','D','E','G','H']] = pd.get_dummies(final_df['êµ¬ë¶„'], drop_first=True).values\n",
    "        cols_order = final_df.columns.tolist()\n",
    "        cols_order.remove('ê³µê¸‰ëŸ‰')\n",
    "        cols_order.insert(len(cols_order), 'ê³µê¸‰ëŸ‰')\n",
    "        final_df = final_df[cols_order]\n",
    "        return final_df\n",
    "    else:\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "russian-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë¶„ ìœ í˜•ë³„ë¡œ predict\n",
    "def get_NMAE(true, pred):\n",
    "    mae = np.abs(true-pred)/true\n",
    "    nmae = round(np.mean(mae), 3)\n",
    "    return nmae\n",
    "\n",
    "def predict_each_gubun(final_df, model, submission_csv, simultaneously=True):\n",
    "    # í†µí•©í•´ì„œ ì˜ˆì¸¡\n",
    "    if simultaneously:\n",
    "        final_df = final_df.set_index(['ì—°ì›”ì¼', 'ì‹œê°„', 'êµ¬ë¶„'])\n",
    "        idx_level = final_df.index.get_level_values\n",
    "        #======================\n",
    "        # Train, Validë¡œ ì„±ëŠ¥ ê²€ì¦\n",
    "        #======================\n",
    "        train = final_df[(idx_level(0) < '2018-09-01')]\n",
    "        train = train.fillna(method='ffill')\n",
    "        valid = final_df[(idx_level(0) >=' 2018-09-01') & (idx_level(0) <= '2018-12-31')]\n",
    "        # X, y ë¶„í• \n",
    "        X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "        X_valid, y_valid = valid.iloc[:, :-1].values, valid['ê³µê¸‰ëŸ‰']\n",
    "        # fit\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict\n",
    "        train_pred = model.predict(X_train)\n",
    "        valid_pred = model.predict(X_valid)\n",
    "        # evaluate\n",
    "        train_nmae = get_NMAE(y_train, train_pred)\n",
    "        valid_nmae = get_NMAE(y_valid, valid_pred)\n",
    "        print(f'# í†µí•© ì˜ˆì¸¡ - Train NAME:', round(train_nmae, 3))\n",
    "        print(f'# í†µí•© ì˜ˆì¸¡ - Valid NMAE:', round(valid_nmae, 3))\n",
    "        #======================\n",
    "        # ëª¨ë‘ í•™ìŠµì‹œí‚¤ê³  Testë¡œ ì˜ˆì¸¡\n",
    "        #======================\n",
    "        train = final_df[(idx_level(0) < '2019-01-01')]\n",
    "        train = train.fillna(method='ffill')\n",
    "        test = final_df[(idx_level(0) >= '2019-01-01')]\n",
    "        # X,y ë¶„í• \n",
    "        X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "        X_test = test.iloc[:, :-1].fillna(method='ffill').values\n",
    "        # fit\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict\n",
    "        test_pred = model.predict(X_test)\n",
    "        submission_csv['ê³µê¸‰ëŸ‰'] = test_pred\n",
    "        return submission_csv\n",
    "        \n",
    "    else:\n",
    "        cols = ['A', 'B', 'C', 'D', 'E', 'G', 'H']\n",
    "        total_test_pred = np.array([])\n",
    "        for col in cols:\n",
    "            gubun_df = final_df[final_df['êµ¬ë¶„'] == col]\n",
    "            gubun_df = gubun_df.set_index(['ì—°ì›”ì¼','ì‹œê°„','êµ¬ë¶„'])\n",
    "\n",
    "            idx_level = gubun_df.index.get_level_values\n",
    "            #======================\n",
    "            # Train, Validë¡œ ì„±ëŠ¥ ê²€ì¦\n",
    "            #======================\n",
    "            train = gubun_df[(idx_level(0) < '2018-01-01')]\n",
    "            train = train.fillna(method='ffill')  # ê²°ì¸¡ì¹˜ ìˆìœ¼ë©´ ì•ˆë„ëŠ” ëª¨ë¸ìš©\n",
    "            valid = gubun_df[(idx_level(0) >= '2018-01-01') & (idx_level(0) <= '2018-03-31')]\n",
    "            # X, y ë¶„í• \n",
    "            X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "            X_valid, y_valid = valid.iloc[:, :-1].values, valid['ê³µê¸‰ëŸ‰']\n",
    "            # fit\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict\n",
    "            train_pred = model.predict(X_train)\n",
    "            valid_pred = model.predict(X_valid)\n",
    "            # evaluate\n",
    "            train_nmae = get_NMAE(y_train, train_pred)\n",
    "            valid_nmae = get_NMAE(y_valid, valid_pred)\n",
    "            print(f'# {col} - Train NAME:', round(train_nmae, 3))\n",
    "            print(f'# {col} - Valid NMAE:', round(valid_nmae, 3))\n",
    "            print()\n",
    "            #======================\n",
    "            # ëª¨ë‘ í•™ìŠµì‹œí‚¤ê³  Testë¡œ ì˜ˆì¸¡\n",
    "            #======================\n",
    "            train = gubun_df[(idx_level(0) < '2019-01-01')]\n",
    "            train = train.fillna(method='ffill')\n",
    "            test = gubun_df[(idx_level(0) >= '2019-01-01')]\n",
    "            # X,y ë¶„í• \n",
    "            X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "            X_test = test.iloc[:, :-1]\n",
    "            X_test = X_test.fillna(method='ffill')  # ê²°ì¸¡ì¹˜ ìˆìœ¼ë©´ ì•ˆë„ëŠ” ëª¨ë¸ìš©\n",
    "            X_test = X_test.values\n",
    "            # fit\n",
    "            model.fit(X_train, y_train)\n",
    "            # predict\n",
    "            test_pred = model.predict(X_test)\n",
    "            total_test_pred = np.append(total_test_pred, test_pred)\n",
    "\n",
    "        submission_csv['ê³µê¸‰ëŸ‰'] = total_test_pred\n",
    "        return submission_csv, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "robust-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# A - Train NAME: 0.117\n",
      "# A - Valid NMAE: 0.164\n",
      "\n",
      "[13:34:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:34:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# B - Train NAME: 0.121\n",
      "# B - Valid NMAE: 0.194\n",
      "\n",
      "[13:34:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:34:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# C - Train NAME: 1.622\n",
      "# C - Valid NMAE: 0.149\n",
      "\n",
      "[13:34:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:34:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# D - Train NAME: 0.115\n",
      "# D - Valid NMAE: 0.148\n",
      "\n",
      "[13:34:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:34:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# E - Train NAME: 0.102\n",
      "# E - Valid NMAE: 0.156\n",
      "\n",
      "[13:34:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:35:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# G - Train NAME: 0.113\n",
      "# G - Valid NMAE: 0.177\n",
      "\n",
      "[13:35:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:35:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# H - Train NAME: 0.118\n",
      "# H - Valid NMAE: 0.169\n",
      "\n",
      "[13:35:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "# 01-03ì›”ë§Œ ì¶”ì¶œ X\n",
    "df = extract_dataset(final_df, split=False)\n",
    "# êµ¬ë¶„ ë¶„ë¦¬ì•ˆí•˜ê³  ë™ì‹œì— ì˜ˆì¸¡\n",
    "df = predict_simultaneously(df, simultaneously=False)\n",
    "\n",
    "# submit\n",
    "submission_csv = pd.read_csv('/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/sample_submission.csv')\n",
    "# model\n",
    "lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "voting_reg = VotingRegressor(estimators=[('lgbm', lgbm),\n",
    "                                        ('xgb', xgb)])\n",
    "\n",
    "submission_csv, test = predict_each_gubun(final_df=df, model=voting_reg, submission_csv=submission_csv,\n",
    "                                          simultaneously=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/submission/'\n",
    "\n",
    "# íŒŒì¼ëª… -> 01-03ì›” ë¶„ë¦¬ì—¬ë¶€_êµ¬ë¶„ìœ í˜•ë¶„ë¦¬ì—¬ë¶€_ëª¨ë¸ì¢…ë¥˜_trainNMAE_validNMAE.csv\n",
    "submission_csv.to_csv(sub_path+'0103False_SimulFalse_xgb+lgbm_cols-autocorr_ratio.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-reserve",
   "metadata": {},
   "source": [
    "## í˜„ì¬ ìƒíƒœ\n",
    "- í˜„ì¬ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥: 0.12679\n",
    "- ì‚¬ìš©í•œ ë°ì´í„°: 01-03ì›”ë§Œ ì‚¬ìš©í•œ ê²ƒì´ ì•„ë‹Œ ëª¨ë“  ë°ì´í„° ë‹¤ ì‚¬ìš©\n",
    "- êµ¬ë¶„ ìœ í˜•ë³„ë¡œ ëª¨ë¸ë§ í–ˆëŠ”ê°€?: Yes! êµ¬ë¶„ ìœ í˜•ë³„ë¡œ ëª¨ë¸ë§ í•¨\n",
    "- ì‚¬ìš©í•œ ë³€ìˆ˜:\n",
    "    - 1ë…„ ì „ ìê¸°ìƒê´€ ë³€ìˆ˜ë“¤\n",
    "    - 1ë…„ ì „ ìê¸°ìƒê´€ ë³€ìˆ˜ë“¤ ê°„ì˜ ë³€í™”ìœ¨\n",
    "- ì‚¬ìš©í•œ ëª¨ë¸:\n",
    "    - XGBoost + LightGBM í•˜ì´ë¸Œë¦¬ë“œ Voting\n",
    "<br><br>\n",
    "- ~~Stacking ëª¨ë¸ ì‹œë„~~\n",
    "- Prophet ì‹œë„\n",
    "- êµ¬ë¶„ ìœ í˜•ë³„ë¡œ ëª¨ë¸ ì¢…ë¥˜ ë‹¬ë¦¬í•´ì„œ ì‹œë„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-austin",
   "metadata": {},
   "source": [
    "### Stacking(1)\n",
    "- ì‚¬ìš©í•œ ë³€ìˆ˜ëŠ” ìœ„ì™€ ë™ì¼(ìê¸°ìƒê´€ë³€ìˆ˜ë“¤ë§Œ ì‚¬ìš©)\n",
    "- Single ëª¨ë¸\n",
    "    - XGBoost\n",
    "    - LightGBM\n",
    "    - Random Forest\n",
    "- ìµœì¢… ë©”íƒ€ ëª¨ë¸: HybridVoting(XGBoost+LightGBM)\n",
    "- **êµ¬ë¶„ ìœ í˜• ì—†ì´ í†µí•©í•´ì„œ ì˜ˆì¸¡**\n",
    "- Test ì„±ëŠ¥ 0.138ë¡œ ì´ì „ë³´ë‹¤ ì˜¤ë²„í”¼íŒ… ë°œìƒ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "impossible-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train shape: (306768, 10) # Test shape: (15120, 10)\n",
      "### Model: LGBMRegressor(random_state=42)\n",
      "# Train pred shape: (306768,) # Test pred shape: (15120,)\n",
      "\n",
      "[14:24:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# Train shape: (306768, 10) # Test shape: (15120, 10)\n",
      "[14:24:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "### Model: XGBRegressor(random_state=42)\n",
      "# Train pred shape: (306768,) # Test pred shape: (15120,)\n",
      "\n",
      "# Train shape: (306768, 10) # Test shape: (15120, 10)\n",
      "### Model: RandomForestRegressor(random_state=42)\n",
      "# Train pred shape: (306768,) # Test pred shape: (15120,)\n",
      "\n",
      "[14:33:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.1\n",
      "ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.191\n",
      "[14:33:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# 1. XGBoostë¡œ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ê°’, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ë°˜í™˜\n",
    "\n",
    "def predict_single_model(final_df, idx_level, model):\n",
    "    #=============================\n",
    "    # Train, Validation ë‚˜ëˆ„ê¸°\n",
    "    #=============================\n",
    "    train_v = final_df[(idx_level(0) < '2018-09-01')].fillna(method='ffill')\n",
    "    valid_v = final_df[(idx_level(0) >= '2018-09-01') & (idx_level(0) <= '2018-12-31')].fillna(method='ffill')\n",
    "    # X, y ë¶„í• \n",
    "    X_train_v, y_train_v = train_v.iloc[:, :-1].values, train_v['ê³µê¸‰ëŸ‰']\n",
    "    X_valid_v, y_valid_v = valid_v.iloc[:, :-1].values, valid_v['ê³µê¸‰ëŸ‰']\n",
    "    # fit\n",
    "    model.fit(X_train_v, y_train_v)\n",
    "    # predict\n",
    "    train_pred_v = model.predict(X_train_v)\n",
    "    valid_pred_v = model.predict(X_valid_v)\n",
    "    \n",
    "    #=============================\n",
    "    # Train, Testë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµ ë° ì˜ˆì¸¡\n",
    "    #=============================\n",
    "    train = final_df[(idx_level(0) < '2019-01-01')].fillna(method='ffill')\n",
    "    test = final_df[(idx_level(0) >= '2019-01-01')].fillna(method='ffill')\n",
    "    print('# Train shape:', train.shape, '# Test shape:', test.shape)\n",
    "    # X, y ë¶„í• \n",
    "    X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "    X_test = test.iloc[:, :-1].values\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    # predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    print('### Model:', model)\n",
    "    print('# Train pred shape:', train_pred.shape, '# Test pred shape:', test_pred.shape)\n",
    "    print()\n",
    "    return train_pred_v, valid_pred_v, train_pred, test_pred\n",
    "\n",
    "\n",
    "def predict_stacking(final_df, meta_model, single_models, submission_csv):\n",
    "    # Multiindexë¡œ ë³€ê²½\n",
    "    final_df = final_df.set_index(['ì—°ì›”ì¼', 'ì‹œê°„', 'êµ¬ë¶„'])\n",
    "    idx_level = final_df.index.get_level_values\n",
    "    # ë©”íƒ€ëª¨ë¸ ì„±ëŠ¥ ì²´í¬í•˜ê¸° ìœ„í•´ yê°’ ë”°ë¡œ ë–¼ë†“ê¸°\n",
    "    y_train_v = final_df[(idx_level(0) < '2018-09-01')]['ê³µê¸‰ëŸ‰'].values\n",
    "    y_valid_v = final_df[(idx_level(0) >= '2018-09-01') & (idx_level(0) <= '2018-12-31')]['ê³µê¸‰ëŸ‰'].values\n",
    "    # ë©”íƒ€ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ í•˜ê¸° ìœ„í•´ yê°’ ë”°ë¡œ ë–¼ë†“ê¸°\n",
    "    y_train = final_df[(idx_level(0) < '2019-01-01')]['ê³µê¸‰ëŸ‰'].values\n",
    "    y_test = final_df[(idx_level(0) >= '2019-01-01')]['ê³µê¸‰ëŸ‰'].values  # ìµœì¢… ì˜ˆì¸¡í•  ê°’ë“¤ì´ë¯€ë¡œ NaNê°’ë“¤ì„!\n",
    "    \n",
    "    #==================================\n",
    "    # ë©”íƒ€ëª¨ë¸ì˜ í•™ìŠµë°ì´í„°ë¡œ ì‚¬ìš©ë  í–‰ë ¬ë“¤ ì´ˆê¸°í™”\n",
    "    #==================================\n",
    "    # ë©”íƒ€ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ìš© ì´ˆê¸°í™” í–‰ë ¬\n",
    "    X_train_v = np.zeros((y_train_v.shape[0], len(single_models)))\n",
    "    X_valid_v = np.zeros((y_valid_v.shape[0], len(single_models)))\n",
    "    # ë©”íƒ€ëª¨ë¸ ìµœì¢… í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™” í–‰ë ¬\n",
    "    X_train = np.zeros((y_train.shape[0], len(single_models)))\n",
    "    X_test = np.zeros((y_test.shape[0], len(single_models)))\n",
    "    \n",
    "    #=======================\n",
    "    # single model í•˜ë‚˜ì”© ìˆ˜í–‰\n",
    "    #=======================\n",
    "    for i, single_model in enumerate(single_models):\n",
    "        train_pred_v, valid_pred_v, train_pred, test_pred = predict_single_model(final_df, idx_level, single_model)\n",
    "        # numpy array concatenate\n",
    "        X_train_v[:, i] = train_pred_v\n",
    "        X_valid_v[:, i] = valid_pred_v\n",
    "        X_train[:, i] = train_pred\n",
    "        X_test[:, i] = test_pred\n",
    "    \n",
    "    #==============================\n",
    "    # ë©”íƒ€ëª¨ë¸ë¡œ ìµœì¢… ì„±ëŠ¥ ê²€ì¦ ë° ìµœì¢… ì˜ˆì¸¡\n",
    "    #==============================\n",
    "    # ì„±ëŠ¥ ê²€ì¦\n",
    "    meta_model.fit(X_train_v, y_train_v)\n",
    "    TRAIN_V_PRED = meta_model.predict(X_train_v)\n",
    "    VALID_V_PRED = meta_model.predict(X_valid_v)\n",
    "    TRAIN_V_NMAE = get_NMAE(y_train_v, TRAIN_V_PRED)\n",
    "    VALID_V_NMAE = get_NMAE(y_valid_v, VALID_V_PRED)\n",
    "    print('ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE:', TRAIN_V_NMAE)\n",
    "    print('ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE:', VALID_V_NMAE)\n",
    "    \n",
    "    # ìµœì¢… ì˜ˆì¸¡\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    FINAL_TEST_PRED = meta_model.predict(X_test)\n",
    "    \n",
    "    # ì œì¶œ csv íŒŒì¼ì— ë‹´ê¸°\n",
    "    submission_csv['ê³µê¸‰ëŸ‰'] = FINAL_TEST_PRED\n",
    "    \n",
    "#     print('ë©”íƒ€ëª¨ë¸ì— ì‚¬ìš©ë  ë°ì´í„°ë“¤')\n",
    "#     print('X_train_v:', X_train_v.shape, 'X_valid_v:', X_valid_v.shape)\n",
    "#     print('y_train_v:', y_train_v.shape, 'y_valid_v:', y_valid_v.shape)\n",
    "#     print()\n",
    "#     print('X_train:', X_train.shape, 'X_test:', X_test.shape)\n",
    "#     print('y_train:', y_train.shape, 'y_test:', y_test.shape)\n",
    "    \n",
    "    return submission_csv\n",
    "    \n",
    "\n",
    "lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "#xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "#rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "META_MODEL = VotingRegressor([('lgbm', lgbm), ('xgb', xgb)])\n",
    "single_models = [lgbm]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "grateful-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/submission/'\n",
    "\n",
    "# íŒŒì¼ëª… -> 01-03ì›” ë¶„ë¦¬ì—¬ë¶€_êµ¬ë¶„ìœ í˜•ë¶„ë¦¬ì—¬ë¶€_ëª¨ë¸ì¢…ë¥˜_trainNMAE_validNMAE.csv\n",
    "submission_csv.to_csv(sub_path+'0103False_SimulFalse_Stacking(xgb+lgbm+rf_meta:voting)_cols-autocorr_ratio.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-delay",
   "metadata": {},
   "source": [
    "---\n",
    "### Stacking(2)\n",
    "- ì‚¬ìš©í•œ ë³€ìˆ˜ëŠ” ìœ„ì™€ ë™ì¼(ìê¸°ìƒê´€ë³€ìˆ˜ë“¤ë§Œ ì‚¬ìš©)\n",
    "- Single ëª¨ë¸\n",
    "    - XGBoost\n",
    "    - LightGBM\n",
    "    - Random Forest\n",
    "- ìµœì¢… ë©”íƒ€ ëª¨ë¸: HybridVoting(XGBoost+LightGBM)\n",
    "- **êµ¬ë¶„ ìœ í˜• ë‚˜ëˆ„ì–´ì„œ ì˜ˆì¸¡**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adequate-material",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ A-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ A -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ A -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[11:53:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ A-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[11:53:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ A -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ A -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ A-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ A -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ A -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ A -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.055\n",
      "ğŸ“Œ A -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.177\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ B-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ B -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ B -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[11:55:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ B-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[11:55:36] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ B -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ B -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ B-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ B -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ B -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ B -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.065\n",
      "ğŸ“Œ B -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.172\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ C-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ C -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ C -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[11:57:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ C-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[11:57:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ C -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ C -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ C-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ C -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ C -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ C -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.277\n",
      "ğŸ“Œ C -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.344\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ D-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ D -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ D -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[11:59:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ D-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[11:59:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ D -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ D -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ D-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ D -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ D -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ D -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.062\n",
      "ğŸ“Œ D -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.168\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ E-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ E -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ E -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[12:01:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ E-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[12:01:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ E -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ E -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ E-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ E -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ E -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ E -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.06\n",
      "ğŸ“Œ E -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.177\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ G-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ G -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ G -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[12:03:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ G-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[12:03:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ G -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ G -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ G-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ G -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ G -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ G -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.047\n",
      "ğŸ“Œ G -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.181\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ H-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ H -> ### Model: LGBMRegressor(n_estimators=200, random_state=42)\n",
      "ğŸ“Œ H -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[12:05:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ H-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[12:05:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ H -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ H -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ H-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ H -> ### Model: RandomForestRegressor(min_samples_split=10, n_estimators=200)\n",
      "ğŸ“Œ H -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ H -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.071\n",
      "ğŸ“Œ H -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.173\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import os\n",
    "\n",
    "def predict_single_model_gubun(final_df, idx_level, model, gubun):\n",
    "    #=============================\n",
    "    # Train, Validation ë‚˜ëˆ„ê¸°\n",
    "    #=============================\n",
    "    train_v = final_df[(idx_level(0) < '2018-09-01')].fillna(method='ffill')\n",
    "    valid_v = final_df[(idx_level(0) >= '2018-09-01') & (idx_level(0) <= '2018-12-31')].fillna(method='ffill')\n",
    "    # X, y ë¶„í• \n",
    "    X_train_v, y_train_v = train_v.iloc[:, :-1].values, train_v['ê³µê¸‰ëŸ‰']\n",
    "    X_valid_v, y_valid_v = valid_v.iloc[:, :-1].values, valid_v['ê³µê¸‰ëŸ‰']\n",
    "    # fit\n",
    "    model.fit(X_train_v, y_train_v)\n",
    "    # predict\n",
    "    train_pred_v = model.predict(X_train_v)\n",
    "    valid_pred_v = model.predict(X_valid_v)\n",
    "    \n",
    "    #=============================\n",
    "    # Train, Testë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµ ë° ì˜ˆì¸¡\n",
    "    #=============================\n",
    "    train = final_df[(idx_level(0) < '2019-01-01')].fillna(method='ffill')\n",
    "    test = final_df[(idx_level(0) >= '2019-01-01')].fillna(method='ffill')\n",
    "    print(f'ğŸ“Œ {gubun}-> # Train shape:', train.shape, '# Test shape:', test.shape)\n",
    "    # X, y ë¶„í• \n",
    "    X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "    X_test = test.iloc[:, :-1].values\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    # predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f'ğŸ“Œ {gubun} -> ### Model:', model)\n",
    "    print(f'ğŸ“Œ {gubun} -> # Train pred shape:', train_pred.shape, '# Test pred shape:', test_pred.shape)\n",
    "    print()\n",
    "    return train_pred_v, valid_pred_v, train_pred, test_pred\n",
    "\n",
    "\n",
    "def predict_stacking_gubun(final_df, meta_model, single_models, gubun='A'):\n",
    "    # ì¸ìë¡œ ë„£ì–´ì¤€ êµ¬ë¶„ ìœ í˜• ë°ì´í„°í”„ë ˆì„\n",
    "    final_df = final_df[final_df['êµ¬ë¶„'] == gubun]\n",
    "    # Multiindexë¡œ ë³€ê²½\n",
    "    final_df = final_df.set_index(['ì—°ì›”ì¼', 'ì‹œê°„', 'êµ¬ë¶„'])\n",
    "    idx_level = final_df.index.get_level_values\n",
    "    # ë©”íƒ€ëª¨ë¸ ì„±ëŠ¥ ì²´í¬í•˜ê¸° ìœ„í•´ yê°’ ë”°ë¡œ ë–¼ë†“ê¸°\n",
    "    y_train_v = final_df[(idx_level(0) < '2018-09-01')]['ê³µê¸‰ëŸ‰'].values\n",
    "    y_valid_v = final_df[(idx_level(0) >= '2018-09-01') & (idx_level(0) <= '2018-12-31')]['ê³µê¸‰ëŸ‰'].values\n",
    "    # ë©”íƒ€ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ í•˜ê¸° ìœ„í•´ yê°’ ë”°ë¡œ ë–¼ë†“ê¸°\n",
    "    y_train = final_df[(idx_level(0) < '2019-01-01')]['ê³µê¸‰ëŸ‰'].values\n",
    "    y_test = final_df[(idx_level(0) >= '2019-01-01')]['ê³µê¸‰ëŸ‰'].values  # ìµœì¢… ì˜ˆì¸¡í•  ê°’ë“¤ì´ë¯€ë¡œ NaNê°’ë“¤ì„!\n",
    "    \n",
    "    #==================================\n",
    "    # ë©”íƒ€ëª¨ë¸ì˜ í•™ìŠµë°ì´í„°ë¡œ ì‚¬ìš©ë  í–‰ë ¬ë“¤ ì´ˆê¸°í™”\n",
    "    #==================================\n",
    "    # ë©”íƒ€ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ìš© ì´ˆê¸°í™” í–‰ë ¬\n",
    "    X_train_v = np.zeros((y_train_v.shape[0], len(single_models)))\n",
    "    X_valid_v = np.zeros((y_valid_v.shape[0], len(single_models)))\n",
    "    # ë©”íƒ€ëª¨ë¸ ìµœì¢… í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™” í–‰ë ¬\n",
    "    X_train = np.zeros((y_train.shape[0], len(single_models)))\n",
    "    X_test = np.zeros((y_test.shape[0], len(single_models)))\n",
    "    \n",
    "    #=======================\n",
    "    # single model í•˜ë‚˜ì”© ìˆ˜í–‰\n",
    "    #=======================\n",
    "    for i, single_model in enumerate(single_models):\n",
    "        train_pred_v, valid_pred_v, train_pred, test_pred = predict_single_model_gubun(final_df, idx_level, \n",
    "                                                                                       single_model, gubun)\n",
    "        # numpy array concatenate\n",
    "        X_train_v[:, i] = train_pred_v\n",
    "        X_valid_v[:, i] = valid_pred_v\n",
    "        X_train[:, i] = train_pred\n",
    "        X_test[:, i] = test_pred\n",
    "    \n",
    "    #==============================\n",
    "    # ë©”íƒ€ëª¨ë¸ë¡œ ìµœì¢… ì„±ëŠ¥ ê²€ì¦ ë° ìµœì¢… ì˜ˆì¸¡\n",
    "    #==============================\n",
    "    # ì„±ëŠ¥ ê²€ì¦\n",
    "    meta_model.fit(X_train_v, y_train_v)\n",
    "    TRAIN_V_PRED = meta_model.predict(X_train_v)\n",
    "    VALID_V_PRED = meta_model.predict(X_valid_v)\n",
    "    TRAIN_V_NMAE = get_NMAE(y_train_v, TRAIN_V_PRED)\n",
    "    VALID_V_NMAE = get_NMAE(y_valid_v, VALID_V_PRED)\n",
    "    print(f'ğŸ“Œ {gubun} -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE:', TRAIN_V_NMAE)\n",
    "    print(f'ğŸ“Œ {gubun} -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE:', VALID_V_NMAE)\n",
    "    \n",
    "    # ìµœì¢… ì˜ˆì¸¡\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    FINAL_TEST_PRED = meta_model.predict(X_test)\n",
    "     \n",
    "#     print('ë©”íƒ€ëª¨ë¸ì— ì‚¬ìš©ë  ë°ì´í„°ë“¤')\n",
    "#     print('X_train_v:', X_train_v.shape, 'X_valid_v:', X_valid_v.shape)\n",
    "#     print('y_train_v:', y_train_v.shape, 'y_valid_v:', y_valid_v.shape)\n",
    "#     print()\n",
    "#     print('X_train:', X_train.shape, 'X_test:', X_test.shape)\n",
    "#     print('y_train:', y_train.shape, 'y_test:', y_test.shape)\n",
    "    print('TEST_LABEL shape:', y_test.shape, 'TEST_PRED shape:', FINAL_TEST_PRED.shape)\n",
    "    return FINAL_TEST_PRED\n",
    "\n",
    "\n",
    "def predict_stacking(final_df, submission_csv, meta_model, single_models: list, gubuns: list):\n",
    "    total_gubun_pred = np.array([])\n",
    "    # ê° êµ¬ë¶„ ìœ í˜• ë³„ë¡œ Stacking ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "    for gubun in gubuns:\n",
    "        gubun_test_pred = predict_stacking_gubun(final_df, meta_model, single_models, gubun)\n",
    "        total_gubun_pred = np.append(total_gubun_pred, gubun_test_pred)\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ì— ì¹¼ëŸ¼ìœ¼ë¡œ ë„£ê¸°\n",
    "    submission_csv['ê³µê¸‰ëŸ‰'] = total_gubun_pred\n",
    "    \n",
    "    return submission_csv\n",
    "\n",
    "single_lgbm = LGBMRegressor(n_estimators=200, random_state=42)\n",
    "single_xgb = XGBRFRegressor(n_estimators=100, random_state=42)\n",
    "single_rf = RandomForestRegressor(n_estimators=200, min_samples_split=10)\n",
    "meta_model = VotingRegressor([('lgbm', single_lgbm), ('xgb', single_xgb), ('rf', single_rf)],\n",
    "                            n_jobs=-1)\n",
    "single_models = [single_lgbm, single_xgb, single_rf]\n",
    "\n",
    "# 01-03ì›”ë§Œ ì¶”ì¶œ X\n",
    "df = extract_dataset(final_df, split=False)\n",
    "gubuns = df['êµ¬ë¶„'].unique()\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ë¡œë“œ\n",
    "sub_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas'\n",
    "submission_csv = pd.read_csv(os.path.join(sub_path, 'sample_submission.csv'))\n",
    "\n",
    "final_submission_csv = predict_stacking(final_df=df, submission_csv=submission_csv,\n",
    "                                        meta_model=meta_model, single_models=single_models,\n",
    "                                        gubuns=gubuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "figured-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/submission'\n",
    "filename = '0103False_SimulFalse_Stacking(lgbm_xgb_rf_meta-voting)_cols-autocorr_ratio.csv'\n",
    "final_submission_csv.to_csv(os.path.join(csv_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-corruption",
   "metadata": {},
   "source": [
    "---\n",
    "### í˜„ì¬ìƒíƒœ + Cìœ í˜•ë§Œ ë”°ë¡œ Prophetìœ¼ë¡œ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "wound-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:18:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# A - Train NAME: 0.117\n",
      "# A - Valid NMAE: 0.164\n",
      "\n",
      "[12:18:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# B - Train NAME: 0.121\n",
      "# B - Valid NMAE: 0.194\n",
      "\n",
      "[12:18:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# C - Train NAME: 1.622\n",
      "# C - Valid NMAE: 0.149\n",
      "\n",
      "[12:18:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# D - Train NAME: 0.115\n",
      "# D - Valid NMAE: 0.148\n",
      "\n",
      "[12:18:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# E - Train NAME: 0.102\n",
      "# E - Valid NMAE: 0.156\n",
      "\n",
      "[12:18:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# G - Train NAME: 0.113\n",
      "# G - Valid NMAE: 0.177\n",
      "\n",
      "[12:18:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "# H - Train NAME: 0.118\n",
      "# H - Valid NMAE: 0.169\n",
      "\n",
      "[12:18:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "# 01-03ì›”ë§Œ ì¶”ì¶œ X\n",
    "df = extract_dataset(final_df, split=False)\n",
    "# êµ¬ë¶„ ë¶„ë¦¬ì•ˆí•˜ê³  ë™ì‹œì— ì˜ˆì¸¡\n",
    "df = predict_simultaneously(df, simultaneously=False)\n",
    "\n",
    "# submit\n",
    "submission_csv = pd.read_csv('/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/sample_submission.csv')\n",
    "# model\n",
    "lgbm = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "voting_reg = VotingRegressor(estimators=[('lgbm', lgbm),\n",
    "                                        ('xgb', xgb)])\n",
    "\n",
    "submission_csv, test = predict_each_gubun(final_df=df, model=voting_reg, submission_csv=submission_csv,\n",
    "                                          simultaneously=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "missing-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cìœ í˜•ì— ëŒ€í•œ ìµœì¢…ì˜ˆì¸¡ ê°’ ì‚­ì œ\n",
    "submission_csv.loc[submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.contains('C'), 'ê³µê¸‰ëŸ‰'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-harmony",
   "metadata": {},
   "source": [
    "- C ìœ í˜•ì— ëŒ€í•´ì„œëŠ” Kats ëª¨ë¸ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "veterinary-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = df[df['êµ¬ë¶„'] == 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "applied-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format_pandas(row):\n",
    "    if row['ì‹œê°„'] == 24:\n",
    "        row['ì—°ì›”ì¼'] += pd.DateOffset(days=1)\n",
    "        row['ì‹œê°„'] = 0\n",
    "    return row\n",
    "\n",
    "c_df = c_df.apply(date_format_pandas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "advance-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df['ì‹œê°„'] = c_df['ì‹œê°„'].apply(lambda x: str(x) if x >= 10 else '0'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "physical-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df['ì—°ì›”ì¼'] = c_df['ì—°ì›”ì¼'].astype(str)\n",
    "c_df['time'] = c_df['ì—°ì›”ì¼'] + ' ' + c_df['ì‹œê°„']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "demonstrated-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df['time'] = pd.to_datetime(c_df['time'], format='%Y-%m-%d %H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "missing-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_kats = c_df[['time', 'ê³µê¸‰ëŸ‰']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "exact-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.consts import TimeSeriesData\n",
    "from kats.models.prophet import ProphetModel, ProphetParams\n",
    "\n",
    "c_train = c_df_kats[c_df_kats['ê³µê¸‰ëŸ‰'].notnull()]\n",
    "c_test = c_df_kats[c_df_kats['ê³µê¸‰ëŸ‰'].isnull()]\n",
    "\n",
    "# Ts ê°ì²´ë¡œ ë³€í™˜\n",
    "c_train_ts = TimeSeriesData(c_train)\n",
    "\n",
    "# Prophet model\n",
    "params = ProphetParams(seasonality_mode='additive')\n",
    "model = ProphetModel(c_train_ts, params)\n",
    "\n",
    "# fit\n",
    "model.fit()\n",
    "\n",
    "# predict\n",
    "c_test_pred = model.predict(steps=c_test.shape[0], freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "primary-video",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>fcst</th>\n",
       "      <th>fcst_lower</th>\n",
       "      <th>fcst_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>196.870784</td>\n",
       "      <td>163.844434</td>\n",
       "      <td>227.595775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>188.341943</td>\n",
       "      <td>157.101997</td>\n",
       "      <td>221.681504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>180.878073</td>\n",
       "      <td>149.262089</td>\n",
       "      <td>212.905692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>178.108334</td>\n",
       "      <td>150.219222</td>\n",
       "      <td>211.316099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05:00:00</td>\n",
       "      <td>182.755447</td>\n",
       "      <td>150.585278</td>\n",
       "      <td>216.352259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2019-03-31 20:00:00</td>\n",
       "      <td>118.725606</td>\n",
       "      <td>75.154668</td>\n",
       "      <td>166.141916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2019-03-31 21:00:00</td>\n",
       "      <td>120.550628</td>\n",
       "      <td>77.043059</td>\n",
       "      <td>163.781934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2019-03-31 22:00:00</td>\n",
       "      <td>117.874770</td>\n",
       "      <td>74.729611</td>\n",
       "      <td>163.380741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2019-03-31 23:00:00</td>\n",
       "      <td>112.624121</td>\n",
       "      <td>70.346437</td>\n",
       "      <td>156.944441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2019-04-01 00:00:00</td>\n",
       "      <td>106.214492</td>\n",
       "      <td>65.154999</td>\n",
       "      <td>151.470436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time        fcst  fcst_lower  fcst_upper\n",
       "0    2019-01-01 01:00:00  196.870784  163.844434  227.595775\n",
       "1    2019-01-01 02:00:00  188.341943  157.101997  221.681504\n",
       "2    2019-01-01 03:00:00  180.878073  149.262089  212.905692\n",
       "3    2019-01-01 04:00:00  178.108334  150.219222  211.316099\n",
       "4    2019-01-01 05:00:00  182.755447  150.585278  216.352259\n",
       "...                  ...         ...         ...         ...\n",
       "2155 2019-03-31 20:00:00  118.725606   75.154668  166.141916\n",
       "2156 2019-03-31 21:00:00  120.550628   77.043059  163.781934\n",
       "2157 2019-03-31 22:00:00  117.874770   74.729611  163.380741\n",
       "2158 2019-03-31 23:00:00  112.624121   70.346437  156.944441\n",
       "2159 2019-04-01 00:00:00  106.214492   65.154999  151.470436\n",
       "\n",
       "[2160 rows x 4 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "pretty-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv['ì¼ì'] = submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[0]\n",
    "submission_csv['ì‹œê°„'] = submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[1]\n",
    "submission_csv['êµ¬ë¶„'] = submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[2]\n",
    "submission_csv['ì¼ì'] = pd.to_datetime(submission_csv['ì¼ì'])\n",
    "submission_csv['ì‹œê°„'] = submission_csv['ì‹œê°„'].astype(int)\n",
    "\n",
    "final_csv = submission_csv[submission_csv['êµ¬ë¶„'] != 'C']\n",
    "c_csv = submission_csv[submission_csv['êµ¬ë¶„'] == 'C']\n",
    "c_csv['ê³µê¸‰ëŸ‰'] = c_test_pred['fcst'].values\n",
    "\n",
    "final_csv = pd.concat([final_csv, c_csv], axis=0).sort_values(by=['êµ¬ë¶„','ì¼ì','ì‹œê°„'])\n",
    "final_csv = final_csv.drop(['ì¼ì','ì‹œê°„','êµ¬ë¶„'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "global-westminster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "higher-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv = submission_csv[submission_csv['êµ¬ë¶„'] != 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "crazy-savings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "universal-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_csv['ê³µê¸‰ëŸ‰'] = c_test_pred['fcst'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "timely-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv = pd.concat([final_csv, c_csv], axis=0).sort_values(by=['êµ¬ë¶„','ì¼ì','ì‹œê°„'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "declared-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv = final_csv.drop(['ì¼ì','ì‹œê°„','êµ¬ë¶„'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "interpreted-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/submission'\n",
    "filename = '0103False_SimulFalse_xgb+lgbm_cols-autocorr_ratio_C_gubun_separated.csv'\n",
    "\n",
    "final_csv.to_csv(os.path.join(csv_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "infinite-shuttle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15120, 2)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-retreat",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-preview",
   "metadata": {},
   "source": [
    "### Stacking(3) + C ìœ í˜•ì€ Prophetìœ¼ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "pleasant-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ A-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ A -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ A -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:24:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ A-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:24:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ A -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ A -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ A-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ A -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ A -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ A -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.071\n",
      "ğŸ“Œ A -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.175\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ B-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ B -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ B -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:26:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ B-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:26:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ B -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ B -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ B-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ B -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ B -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ B -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.081\n",
      "ğŸ“Œ B -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.172\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ C-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ C -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ C -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:28:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ C-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:28:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ C -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ C -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ C-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ C -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ C -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ C -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.352\n",
      "ğŸ“Œ C -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.343\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ D-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ D -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ D -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:30:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ D-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:30:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ D -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ D -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ D-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ D -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ D -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ D -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.077\n",
      "ğŸ“Œ D -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.167\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ E-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ E -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ E -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:32:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ E-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:32:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ E -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ E -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ E-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ E -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ E -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ E -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.072\n",
      "ğŸ“Œ E -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.175\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ G-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ G -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ G -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:34:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ G-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:34:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ G -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ G -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ G-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ G -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ G -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ G -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.063\n",
      "ğŸ“Œ G -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.172\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n",
      "ğŸ“Œ H-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ H -> ### Model: LGBMRegressor(min_child_samples=40, n_estimators=200, random_state=42)\n",
      "ğŸ“Œ H -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "[13:36:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ H-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "[13:36:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "ğŸ“Œ H -> ### Model: XGBRFRegressor(random_state=42)\n",
      "ğŸ“Œ H -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ H-> # Train shape: (43824, 10) # Test shape: (2160, 10)\n",
      "ğŸ“Œ H -> ### Model: RandomForestRegressor(min_samples_split=20, n_estimators=200)\n",
      "ğŸ“Œ H -> # Train pred shape: (43824,) # Test pred shape: (2160,)\n",
      "\n",
      "ğŸ“Œ H -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE: 0.084\n",
      "ğŸ“Œ H -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE: 0.171\n",
      "TEST_LABEL shape: (2160,) TEST_PRED shape: (2160,)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import os\n",
    "\n",
    "def predict_single_model_gubun(final_df, idx_level, model, gubun):\n",
    "    #=============================\n",
    "    # Train, Validation ë‚˜ëˆ„ê¸°\n",
    "    #=============================\n",
    "    train_v = final_df[(idx_level(0) < '2018-09-01')].fillna(method='ffill')\n",
    "    valid_v = final_df[(idx_level(0) >= '2018-09-01') & (idx_level(0) <= '2018-12-31')].fillna(method='ffill')\n",
    "    # X, y ë¶„í• \n",
    "    X_train_v, y_train_v = train_v.iloc[:, :-1].values, train_v['ê³µê¸‰ëŸ‰']\n",
    "    X_valid_v, y_valid_v = valid_v.iloc[:, :-1].values, valid_v['ê³µê¸‰ëŸ‰']\n",
    "    # fit\n",
    "    model.fit(X_train_v, y_train_v)\n",
    "    # predict\n",
    "    train_pred_v = model.predict(X_train_v)\n",
    "    valid_pred_v = model.predict(X_valid_v)\n",
    "    \n",
    "    #=============================\n",
    "    # Train, Testë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµ ë° ì˜ˆì¸¡\n",
    "    #=============================\n",
    "    train = final_df[(idx_level(0) < '2019-01-01')].fillna(method='ffill')\n",
    "    test = final_df[(idx_level(0) >= '2019-01-01')].fillna(method='ffill')\n",
    "    print(f'ğŸ“Œ {gubun}-> # Train shape:', train.shape, '# Test shape:', test.shape)\n",
    "    # X, y ë¶„í• \n",
    "    X_train, y_train = train.iloc[:, :-1].values, train['ê³µê¸‰ëŸ‰']\n",
    "    X_test = test.iloc[:, :-1].values\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    # predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f'ğŸ“Œ {gubun} -> ### Model:', model)\n",
    "    print(f'ğŸ“Œ {gubun} -> # Train pred shape:', train_pred.shape, '# Test pred shape:', test_pred.shape)\n",
    "    print()\n",
    "    return train_pred_v, valid_pred_v, train_pred, test_pred\n",
    "\n",
    "\n",
    "def predict_stacking_gubun(final_df, meta_model, single_models, gubun='A'):\n",
    "    # ì¸ìë¡œ ë„£ì–´ì¤€ êµ¬ë¶„ ìœ í˜• ë°ì´í„°í”„ë ˆì„\n",
    "    final_df = final_df[final_df['êµ¬ë¶„'] == gubun]\n",
    "    # Multiindexë¡œ ë³€ê²½\n",
    "    final_df = final_df.set_index(['ì—°ì›”ì¼', 'ì‹œê°„', 'êµ¬ë¶„'])\n",
    "    idx_level = final_df.index.get_level_values\n",
    "    # ë©”íƒ€ëª¨ë¸ ì„±ëŠ¥ ì²´í¬í•˜ê¸° ìœ„í•´ yê°’ ë”°ë¡œ ë–¼ë†“ê¸°\n",
    "    y_train_v = final_df[(idx_level(0) < '2018-09-01')]['ê³µê¸‰ëŸ‰'].values\n",
    "    y_valid_v = final_df[(idx_level(0) >= '2018-09-01') & (idx_level(0) <= '2018-12-31')]['ê³µê¸‰ëŸ‰'].values\n",
    "    # ë©”íƒ€ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ í•˜ê¸° ìœ„í•´ yê°’ ë”°ë¡œ ë–¼ë†“ê¸°\n",
    "    y_train = final_df[(idx_level(0) < '2019-01-01')]['ê³µê¸‰ëŸ‰'].values\n",
    "    y_test = final_df[(idx_level(0) >= '2019-01-01')]['ê³µê¸‰ëŸ‰'].values  # ìµœì¢… ì˜ˆì¸¡í•  ê°’ë“¤ì´ë¯€ë¡œ NaNê°’ë“¤ì„!\n",
    "    \n",
    "    #==================================\n",
    "    # ë©”íƒ€ëª¨ë¸ì˜ í•™ìŠµë°ì´í„°ë¡œ ì‚¬ìš©ë  í–‰ë ¬ë“¤ ì´ˆê¸°í™”\n",
    "    #==================================\n",
    "    # ë©”íƒ€ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ìš© ì´ˆê¸°í™” í–‰ë ¬\n",
    "    X_train_v = np.zeros((y_train_v.shape[0], len(single_models)))\n",
    "    X_valid_v = np.zeros((y_valid_v.shape[0], len(single_models)))\n",
    "    # ë©”íƒ€ëª¨ë¸ ìµœì¢… í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™” í–‰ë ¬\n",
    "    X_train = np.zeros((y_train.shape[0], len(single_models)))\n",
    "    X_test = np.zeros((y_test.shape[0], len(single_models)))\n",
    "    \n",
    "    #=======================\n",
    "    # single model í•˜ë‚˜ì”© ìˆ˜í–‰\n",
    "    #=======================\n",
    "    for i, single_model in enumerate(single_models):\n",
    "        train_pred_v, valid_pred_v, train_pred, test_pred = predict_single_model_gubun(final_df, idx_level, \n",
    "                                                                                       single_model, gubun)\n",
    "        # numpy array concatenate\n",
    "        X_train_v[:, i] = train_pred_v\n",
    "        X_valid_v[:, i] = valid_pred_v\n",
    "        X_train[:, i] = train_pred\n",
    "        X_test[:, i] = test_pred\n",
    "    \n",
    "    #==============================\n",
    "    # ë©”íƒ€ëª¨ë¸ë¡œ ìµœì¢… ì„±ëŠ¥ ê²€ì¦ ë° ìµœì¢… ì˜ˆì¸¡\n",
    "    #==============================\n",
    "    # ì„±ëŠ¥ ê²€ì¦\n",
    "    meta_model.fit(X_train_v, y_train_v)\n",
    "    TRAIN_V_PRED = meta_model.predict(X_train_v)\n",
    "    VALID_V_PRED = meta_model.predict(X_valid_v)\n",
    "    TRAIN_V_NMAE = get_NMAE(y_train_v, TRAIN_V_PRED)\n",
    "    VALID_V_NMAE = get_NMAE(y_valid_v, VALID_V_PRED)\n",
    "    print(f'ğŸ“Œ {gubun} -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Train NMAE:', TRAIN_V_NMAE)\n",
    "    print(f'ğŸ“Œ {gubun} -> ğŸ”¥ìµœì¢… ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦- Valid NMAE:', VALID_V_NMAE)\n",
    "    \n",
    "    # ìµœì¢… ì˜ˆì¸¡\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    FINAL_TEST_PRED = meta_model.predict(X_test)\n",
    "     \n",
    "#     print('ë©”íƒ€ëª¨ë¸ì— ì‚¬ìš©ë  ë°ì´í„°ë“¤')\n",
    "#     print('X_train_v:', X_train_v.shape, 'X_valid_v:', X_valid_v.shape)\n",
    "#     print('y_train_v:', y_train_v.shape, 'y_valid_v:', y_valid_v.shape)\n",
    "#     print()\n",
    "#     print('X_train:', X_train.shape, 'X_test:', X_test.shape)\n",
    "#     print('y_train:', y_train.shape, 'y_test:', y_test.shape)\n",
    "    print('TEST_LABEL shape:', y_test.shape, 'TEST_PRED shape:', FINAL_TEST_PRED.shape)\n",
    "    return FINAL_TEST_PRED\n",
    "\n",
    "\n",
    "def predict_stacking(final_df, submission_csv, meta_model, single_models: list, gubuns: list):\n",
    "    total_gubun_pred = np.array([])\n",
    "    # ê° êµ¬ë¶„ ìœ í˜• ë³„ë¡œ Stacking ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "    for gubun in gubuns:\n",
    "        gubun_test_pred = predict_stacking_gubun(final_df, meta_model, single_models, gubun)\n",
    "        total_gubun_pred = np.append(total_gubun_pred, gubun_test_pred)\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ì— ì¹¼ëŸ¼ìœ¼ë¡œ ë„£ê¸°\n",
    "    submission_csv['ê³µê¸‰ëŸ‰'] = total_gubun_pred\n",
    "    \n",
    "    return submission_csv\n",
    "\n",
    "single_lgbm = LGBMRegressor(n_estimators=200, random_state=42, min_child_samples=40)\n",
    "single_xgb = XGBRFRegressor(n_estimators=100, random_state=42)\n",
    "single_rf = RandomForestRegressor(n_estimators=200, min_samples_split=20)\n",
    "meta_model = VotingRegressor([('lgbm', single_lgbm), ('xgb', single_xgb), ('rf', single_rf)],\n",
    "                            n_jobs=-1)\n",
    "single_models = [single_lgbm, single_xgb, single_rf]\n",
    "\n",
    "# 01-03ì›”ë§Œ ì¶”ì¶œ X\n",
    "df = extract_dataset(final_df, split=False)\n",
    "gubuns = df['êµ¬ë¶„'].unique()\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ë¡œë“œ\n",
    "sub_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas'\n",
    "submission_csv = pd.read_csv(os.path.join(sub_path, 'sample_submission.csv'))\n",
    "\n",
    "final_submission_csv = predict_stacking(final_df=df, submission_csv=submission_csv,\n",
    "                                        meta_model=meta_model, single_models=single_models,\n",
    "                                        gubuns=gubuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "incident-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = final_submission_csv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "spanish-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_test_pred # <- Cìœ í˜• Prophetìœ¼ë¡œ ì˜ˆì¸¡í•œ ê°’ë“¤ì–´ìˆìŒ\n",
    "\n",
    "submission_csv['ì¼ì'] = submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[0]\n",
    "submission_csv['ì‹œê°„'] = submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[1]\n",
    "submission_csv['êµ¬ë¶„'] = submission_csv['ì¼ì|ì‹œê°„|êµ¬ë¶„'].str.split(' ', expand=True)[2]\n",
    "submission_csv['ì¼ì'] = pd.to_datetime(submission_csv['ì¼ì'])\n",
    "submission_csv['ì‹œê°„'] = submission_csv['ì‹œê°„'].astype(int)\n",
    "\n",
    "final_csv = submission_csv[submission_csv['êµ¬ë¶„'] != 'C']\n",
    "c_csv = submission_csv[submission_csv['êµ¬ë¶„'] == 'C']\n",
    "c_csv['ê³µê¸‰ëŸ‰'] = c_test_pred['fcst'].values\n",
    "\n",
    "final_csv = pd.concat([final_csv, c_csv], axis=0).sort_values(by=['êµ¬ë¶„','ì¼ì','ì‹œê°„'])\n",
    "final_csv = final_csv.drop(['ì¼ì','ì‹œê°„','êµ¬ë¶„'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "crucial-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/Users/younghun/Desktop/gitrepo/KaggleStruggle/dacon_gas/submission'\n",
    "filename = '0103False_SimulFalse_Stacking(xgb+lgbm+rf-meta:Voting)_cols-autocorr_ratio_C_gubun_separated_Prophet.csv'\n",
    "\n",
    "final_csv.to_csv(os.path.join(csv_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-federal",
   "metadata": {},
   "source": [
    "- Stackingì´ ë” ì„±ëŠ¥ì´ ì˜¤ë¥´ì§„ ì•Šë„¤..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-walter",
   "metadata": {},
   "source": [
    "---\n",
    "### ë‹¤ì‹œ ìê¸°ìƒê´€ ë³€ìˆ˜ FEìœ¼ë¡œ ëŒì•„ê°€ê¸° + êµ¬ë¶„ ìœ í˜• ë³„ë¡œ ë”°ë¡œ ëª¨ë¸ ë§Œë“¤ê¸°\n",
    "- 1. êµ¬ë¶„ ìœ í˜• ë³„ë¡œ ì¼ë³€ëŸ‰ Prophet ëŒë ¤ì„œ ì„±ëŠ¥ ì²´í¬í•´ë³´ê¸°\n",
    "- 2. ìê¸°ìƒê´€ ë³€ìˆ˜ FE ì¶”ê°€ í›„ XGB+LGBM VotingRegressor(í˜„ì¬ ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸) -> ì˜ˆì¸¡ì„±ëŠ¥ ì²´í¬\n",
    "- 3. êµ¬ë¶„ ìœ í˜• ë³„ë¡œ ë‹¤ë³€ëŸ‰ Prophet ëŒë ¤ì„œ ì„±ëŠ¥ ì²´í¬\n",
    "- ë§Œì•½, Prophetì´ ë” ì„±ëŠ¥ì´ ì¢‹ë‹¤ë©´ Prophetì—ì„œ íŒŒë¼ë¯¸í„° íŠœë‹..?\n",
    "- ë§Œì•½, 2ë²ˆì˜ ì„±ëŠ¥ì´ ì—¬ì „íˆ ê°€ì¥ ì¢‹ë‹¤ë©´ Prophet ë²„ë¦¬ê³  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ë‹¤ì–‘í™”..(Stackingì€ ë„ˆë¬´ ì˜¤ë²„í”¼íŒ… ë˜ëŠ”ë“¯..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-child",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
